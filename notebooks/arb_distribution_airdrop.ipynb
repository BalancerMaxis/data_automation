{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch pool snapshots from balancer subgraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# Query:\n",
    "POOLS_SNAPSHOTS_QUERY = \"\"\"\n",
    "{{\n",
    "  poolSnapshots(\n",
    "    first: {first}\n",
    "    skip: {skip}\n",
    "    orderBy: timestamp\n",
    "    orderDirection: desc\n",
    "    where: {{timestamp_gte: {start_ts}, timestamp_lt: {end_ts}}}\n",
    "  ) {{\n",
    "    pool {{\n",
    "      address\n",
    "      id\n",
    "      symbol\n",
    "    }}\n",
    "    timestamp\n",
    "    protocolFee\n",
    "    swapFees\n",
    "    swapVolume\n",
    "    liquidity\n",
    "  }}\n",
    "}}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T17:31:28.287031Z",
     "start_time": "2023-09-11T17:31:28.273809Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected data for dates: 2023-08-24 00:00:00 - 2023-09-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "\n",
    "from gql import Client\n",
    "from gql import gql\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "BALANCER_GRAPH_URL = \"https://api.thegraph.com/subgraphs/name/balancer-labs/balancer-arbitrum-v2\"\n",
    "\n",
    "# Start date and end date are the following: start date is always previous Thursday 00:00 UTC, end date is always this Thursday 00:00 UTC:\n",
    "today = datetime.today()\n",
    "# Calculate days until previous Thursday (0 = Monday, 3 = Thursday)\n",
    "# Calculate days until thursday that was 2 weeks ago\n",
    "# days_until_thursday_two_weeks_ago = (today.weekday() - 3) % 7 + 7\n",
    "# # Calculate start date by subtracting days_until_previous_thursday and setting time to 00:00\n",
    "# start_date = today - timedelta(days=days_until_thursday_two_weeks_ago, hours=today.hour, minutes=today.minute,\n",
    "#                                seconds=today.second, microseconds=today.microsecond)\n",
    "# # Calculate end date by adding 7 days to the start date\n",
    "# end_date = start_date + timedelta(days=14)\n",
    "# 24 Aug 2023\n",
    "start_date = datetime(2023, 8, 24)\n",
    "end_date = start_date + timedelta(days=14)\n",
    "start_ts = int(start_date.timestamp())\n",
    "end_ts = int(end_date.timestamp())\n",
    "\n",
    "\n",
    "# Fetch all the data from the balancer subgraph\n",
    "def make_gql_client(url: str) -> Optional[Client]:\n",
    "    transport = RequestsHTTPTransport(url=url, retries=3)\n",
    "    return Client(\n",
    "        transport=transport, fetch_schema_from_transport=True, execute_timeout=60\n",
    "    )\n",
    "\n",
    "\n",
    "def get_balancer_pool_snapshots() -> Optional[List[Dict]]:\n",
    "    client = make_gql_client(BALANCER_GRAPH_URL)\n",
    "    all_pools = []\n",
    "    limit = 100\n",
    "    offset = 0\n",
    "    while True:\n",
    "        result = client.execute(\n",
    "            gql(POOLS_SNAPSHOTS_QUERY.format(first=limit, skip=offset, start_ts=start_ts, end_ts=end_ts)))\n",
    "        all_pools.extend(result['poolSnapshots'])\n",
    "        offset += limit\n",
    "        if len(result['poolSnapshots']) < limit - 1:\n",
    "            break\n",
    "    return all_pools\n",
    "\n",
    "\n",
    "pool_snapshots = get_balancer_pool_snapshots()\n",
    "\n",
    "print(f\"Collected data for dates: {start_date} - {end_date}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T17:31:36.785286Z",
     "start_time": "2023-09-11T17:31:28.279537Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate BAL emissions per week:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current BAL emissions per week: 121929.98021178861\n"
     ]
    }
   ],
   "source": [
    "current_year = 2023\n",
    "emissions_per_week = 0\n",
    "with open('../data/emissionsPerYear.json') as f:\n",
    "    data = json.load(f)\n",
    "for item in data['data']:\n",
    "    if item['year'] == str(current_year):\n",
    "        emissions_per_week = float(item['balPerWeek'])\n",
    "        break\n",
    "print(f'Current BAL emissions per week: {emissions_per_week}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T17:31:36.785758Z",
     "start_time": "2023-09-11T17:31:36.780090Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process all the data in this cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from web3 import Web3\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ARB_CHAIN_ID = 42161\n",
    "BALANCER_GAUGE_URL = \"https://api.thegraph.com/subgraphs/name/balancer-labs/balancer-gauges\"\n",
    "BALANCER_GAUGE_CONTROLLER_ADDR = Web3.toChecksumAddress(\"0xC128468b7Ce63eA702C1f104D55A2566b13D3ABD\")\n",
    "BALANCER_GAUGE_CONTROLLER_ABI = [{\"stateMutability\": \"view\", \"type\": \"function\", \"name\": \"gauge_relative_weight\",\n",
    "                                  \"inputs\": [{\"name\": \"addr\", \"type\": \"address\"}],\n",
    "                                  \"outputs\": [{\"name\": \"\", \"type\": \"uint256\"}]},\n",
    "                                 {\"stateMutability\": \"view\", \"type\": \"function\", \"name\": \"gauge_relative_weight\",\n",
    "                                  \"inputs\": [{\"name\": \"addr\", \"type\": \"address\"}, {\"name\": \"time\", \"type\": \"uint256\"}],\n",
    "                                  \"outputs\": [{\"name\": \"\", \"type\": \"uint256\"}]}]\n",
    "\n",
    "web3 = Web3(Web3.HTTPProvider(os.environ[\"ETHNODEURL\"]))\n",
    "\n",
    "# fetch balancer token usd price:\n",
    "cg = CoinGeckoAPI()\n",
    "bal_token_price = cg.get_price(ids='balancer', vs_currencies='usd')['balancer']['usd']\n",
    "# Fetch all voting gauges from github json\n",
    "voting_gauges_req = requests.get(\n",
    "    \"https://raw.githubusercontent.com/balancer/frontend-v2/master/src/data/voting-gauges.json\")\n",
    "if not voting_gauges_req.ok:\n",
    "    raise ValueError(\"Failed to fetch voting gauges\")\n",
    "voting_gauges = voting_gauges_req.json()\n",
    "\n",
    "# Collect arb gauges\n",
    "arb_gauges = {}\n",
    "for gauge in voting_gauges:\n",
    "    # Only collect gauges for the arb chain and that are not killed\n",
    "    if int(gauge['network']) == ARB_CHAIN_ID and gauge['isKilled'] is False:\n",
    "        arb_gauges[gauge['address']] = {\n",
    "            'gaugeAddress': gauge['address'],\n",
    "            'pool': gauge['pool']['address'],\n",
    "            'symbol': gauge['pool']['symbol'],\n",
    "            'id': gauge['pool']['id'],\n",
    "        }\n",
    "\n",
    "gauge_c_contract = web3.eth.contract(address=BALANCER_GAUGE_CONTROLLER_ADDR, abi=BALANCER_GAUGE_CONTROLLER_ABI)\n",
    "\n",
    "boost_data = {}\n",
    "cap_override_data = {}\n",
    "# Before, load boost data from the file\n",
    "with open('../data/arbitrumGrantGuageMetadata.json') as f:\n",
    "    boosties = json.load(f)\n",
    "    for boost in boosties:\n",
    "        boost_data[boost['gaugeAddress']] = boost.get('fixedBoost', 1)\n",
    "        cap_override_data[boost['gaugeAddress']] = boost.get('capOverride', 10)\n",
    "pool_protocol_fees = {}\n",
    "# Collect protocol fees from the pool snapshots:\n",
    "# TODO: Doesn't work properly as there can be multiple snapshots per pool per week\n",
    "for gauge_addr, gauge_data in arb_gauges.items():\n",
    "    for pool_snapshot in pool_snapshots:\n",
    "        if Web3.toChecksumAddress(pool_snapshot['pool']['address']) == Web3.toChecksumAddress(gauge_data['pool']):\n",
    "            # Since snapshots are sorted by timestamp descending, we can just take the first one we find for each pool and break\n",
    "            protocol_fee = float(pool_snapshot['protocolFee']) if pool_snapshot['protocolFee'] else 0\n",
    "            pool_protocol_fees[gauge_addr] = protocol_fee\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T17:31:37.313212Z",
     "start_time": "2023-09-11T17:31:36.791805Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# Apply boost data to arb gauges\n",
    "vote_weights = {}\n",
    "combined_boost = {}\n",
    "# Dynamic boost data to print out in the final table\n",
    "dynamic_boosts = {}\n",
    "# Collect gauge voting weights from the gauge controller on chain\n",
    "for gauge_addr, gauge_data in arb_gauges.items():\n",
    "    weight = gauge_c_contract.functions.gauge_relative_weight(gauge_addr).call() / 1e18 * 100\n",
    "    # Calculate dynamic boost. Formula is `[Fees earned/value of bal emitted per pool + 1]`\n",
    "    dollar_value_of_bal_emitted = weight * emissions_per_week * bal_token_price\n",
    "    if dollar_value_of_bal_emitted != 0:\n",
    "        dynamic_boost = (pool_protocol_fees.get(gauge_addr, 0) / dollar_value_of_bal_emitted) + 1\n",
    "    else:\n",
    "        dynamic_boost = 1\n",
    "    dynamic_boosts[gauge_addr] = dynamic_boost\n",
    "    # Now calculate the final boost value, which uses formula - (dynamic boost + fixed boost) - 1\n",
    "    boost = (dynamic_boost + boost_data.get(gauge_addr, 1)) - 1\n",
    "    combined_boost[gauge_addr] = boost\n",
    "    weight *= boost\n",
    "    vote_weights[gauge_addr] = weight\n",
    "    arb_gauges[gauge_addr]['voteWeight'] = weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T17:31:43.044269Z",
     "start_time": "2023-09-11T17:31:37.317255Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate arbitrum distribution across gauges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspent arb: 0.0\n",
      "Arb distributed: 65000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>recipientGaugeAddr</th>\n      <th>pool</th>\n      <th>symbol</th>\n      <th>voteWeight</th>\n      <th>distribution</th>\n      <th>%distribution</th>\n      <th>boost</th>\n      <th>staticBoost</th>\n      <th>dynamicBoost</th>\n      <th>cap</th>\n      <th>withBonus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0x2eB5661002b68EBE887d29d415c3A3b52536912C</td>\n      <td>0x4a2F6Ae7F3e5D715689530873ec35593Dc28951B</td>\n      <td>wstETH/rETH/cbETH</td>\n      <td>1.428695</td>\n      <td>13000.000000</td>\n      <td>20.000000</td>\n      <td>1.755373</td>\n      <td>1.75</td>\n      <td>1.005373</td>\n      <td>20%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0xd6B875d62c2661eaB66472F36c672e4B512f1135</td>\n      <td>0xadE4A71BB62bEc25154CFc7e6ff49A513B491E81</td>\n      <td>rETH-WETH-BPT</td>\n      <td>1.114425</td>\n      <td>9663.883442</td>\n      <td>14.867513</td>\n      <td>1.752091</td>\n      <td>1.75</td>\n      <td>1.002091</td>\n      <td>20%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0xcf9f895296F5e1D66a7D4dcf1d92e1B435E9f999</td>\n      <td>0x32dF62dc3aEd2cD6224193052Ce665DC18165841</td>\n      <td>RDNT-WETH</td>\n      <td>2.643029</td>\n      <td>6500.000000</td>\n      <td>10.000000</td>\n      <td>2.572007</td>\n      <td>1.50</td>\n      <td>2.072007</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0xd956246EA5b06DEa930F0A7feC1FFf000436e3f2</td>\n      <td>0x8bc65Eed474D1A00555825c91FeAb6A8255C2107</td>\n      <td>DOLA/USDC BPT</td>\n      <td>1.101374</td>\n      <td>6500.000000</td>\n      <td>10.000000</td>\n      <td>1.000526</td>\n      <td>1.00</td>\n      <td>1.000526</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0x82d2c7B67Eaa5028c89BE86CeA8e1DF5bd2119A1</td>\n      <td>0xc7FA3A3527435720f0e2a4c1378335324dd4F9b3</td>\n      <td>55auraBal-45wsteth</td>\n      <td>0.821184</td>\n      <td>6500.000000</td>\n      <td>10.000000</td>\n      <td>1.005313</td>\n      <td>1.00</td>\n      <td>1.005313</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0x260cbb867359a1084eC97de4157d06ca74e89415</td>\n      <td>0x9791d590788598535278552EEcD4b211bFc790CB</td>\n      <td>wstETH-WETH-BPT</td>\n      <td>0.597440</td>\n      <td>4945.325305</td>\n      <td>7.608193</td>\n      <td>1.765447</td>\n      <td>1.75</td>\n      <td>1.015447</td>\n      <td>20%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0xfC745035F31BCbaEb2D1a89aA9171495c671F6cE</td>\n      <td>0x3FD4954a851eaD144c2FF72B1f5a38Ea5976Bd54</td>\n      <td>ankrETH/wstETH-BPT</td>\n      <td>0.471507</td>\n      <td>4536.735399</td>\n      <td>6.979593</td>\n      <td>1.754890</td>\n      <td>1.75</td>\n      <td>1.004890</td>\n      <td>20%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0x011417BBED6FC9cefF36C032D431b0eFcBA7f8B3</td>\n      <td>0xc9f52540976385A84BF416903e1Ca3983c539E34</td>\n      <td>50tBTC-50WETH</td>\n      <td>0.424208</td>\n      <td>4281.578350</td>\n      <td>6.587044</td>\n      <td>1.009510</td>\n      <td>1.00</td>\n      <td>1.009510</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0x8F0B53F3BA19Ee31C0A73a6F6D84106340fadf5f</td>\n      <td>0x36bf227d6BaC96e2aB1EbB5492ECec69C691943f</td>\n      <td>B-wstETH-WETH-Stable</td>\n      <td>0.308965</td>\n      <td>3229.700967</td>\n      <td>4.968771</td>\n      <td>2.335431</td>\n      <td>1.00</td>\n      <td>2.335431</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0xa14453084318277b11d38FbE05D857A4f647442B</td>\n      <td>0x423A1323c871aBC9d89EB06855bF5347048Fc4A5</td>\n      <td>4POOL-BPT</td>\n      <td>0.281796</td>\n      <td>12473.359672</td>\n      <td>3.805169</td>\n      <td>1.006195</td>\n      <td>1.00</td>\n      <td>1.006195</td>\n      <td>10%</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <td>0xb438c6cc53315FfA3fcD1bc8b27d6c3155b0B56A</td>\n      <td>0x542F16DA0efB162D20bF4358EfA095B70A100f9E</td>\n      <td>2BTC</td>\n      <td>0.226401</td>\n      <td>2318.349488</td>\n      <td>3.566692</td>\n      <td>1.023678</td>\n      <td>1.00</td>\n      <td>1.023678</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0x04fc019017eD3F921D5ec11fFf84B870744BA0d1</td>\n      <td>0xa231aEa07Bb5e79aE162f95903806FC5AD65fF11</td>\n      <td>50DFX-50WETH</td>\n      <td>0.093369</td>\n      <td>917.818104</td>\n      <td>1.412028</td>\n      <td>1.000170</td>\n      <td>1.00</td>\n      <td>1.000170</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <td>0xeF767E740D83d410794519c2F93Db32e44359a5C</td>\n      <td>0xb3028Ca124B80CFE6E9CA57B70eF2F0CCC41eBd4</td>\n      <td>50MAGIC-50USDC</td>\n      <td>0.012736</td>\n      <td>133.249274</td>\n      <td>0.204999</td>\n      <td>695.220159</td>\n      <td>1.00</td>\n      <td>695.220159</td>\n      <td>10%</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebooks import get_abi\n",
    "from IPython.core.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "ARBITRUM_TO_DISTRIBUTE = 65_000  # 65k arb to distribute to the gauges from airdrop\n",
    "ARBITRUM_TO_USD_POOL = 10_000  # Constant pool of arb to usd\n",
    "VOTE_CAP_IN_PERCENT = 10  # 10% cap on any single gauge\n",
    "ARB_GAUGE_WITH_BONUS = Web3.toChecksumAddress(\"0xa14453084318277b11d38FbE05D857A4f647442B\")\n",
    "ARB_ROOT_GAUGE = Web3.toChecksumAddress(\"0xBb1a15dfd849bc5a6F33C002999c8953aFA626Ad\")\n",
    "VOTE_CAPS_IN_PERCENTS = {gauge_addr: cap_override_data.get(gauge_addr, VOTE_CAP_IN_PERCENT) for gauge_addr in\n",
    "                         arb_gauges.keys()}\n",
    "# Custom gauge caps taken from boost data\n",
    "VOTE_CAPS = {gauge_addr: VOTE_CAPS_IN_PERCENTS[gauge_addr] / 100 * ARBITRUM_TO_DISTRIBUTE for gauge_addr in\n",
    "             arb_gauges.keys()}\n",
    "\n",
    "# Calculate total weight\n",
    "total_weight = sum([gauge['voteWeight'] for gauge in arb_gauges.values()])\n",
    "arb_gauge_distributions = {\n",
    "    \n",
    "}\n",
    "for gauge_addr, gauge_data in arb_gauges.items():\n",
    "    # Calculate distribution based on vote weight and total weight\n",
    "    to_distribute = ARBITRUM_TO_DISTRIBUTE * gauge_data['voteWeight'] / total_weight\n",
    "    # Cap distribution\n",
    "    to_distribute = to_distribute if to_distribute < VOTE_CAPS[gauge_addr] else VOTE_CAPS[gauge_addr]\n",
    "    # Get arb gauge addr\n",
    "    mainnet_arb_root_gauge_contract = web3.eth.contract(\n",
    "        address=Web3.toChecksumAddress(gauge_addr),\n",
    "        abi=get_abi(\"ArbRootGauge\")\n",
    "    )\n",
    "    arb_gauge_distributions[gauge_addr] = {\n",
    "        # 'gaugeAddress': gauge_addr,\n",
    "        'recipientGaugeAddr': mainnet_arb_root_gauge_contract.functions.getRecipient().call(),\n",
    "        'pool': gauge_data['pool'],\n",
    "        'symbol': gauge_data['symbol'],\n",
    "        'voteWeight': gauge_data['voteWeight'],\n",
    "        'distribution': to_distribute if to_distribute < VOTE_CAPS[gauge_addr] else VOTE_CAPS[gauge_addr],\n",
    "        '%distribution': to_distribute / ARBITRUM_TO_DISTRIBUTE * 100,\n",
    "        'boost': combined_boost.get(gauge_addr, 1),\n",
    "        'staticBoost': boost_data.get(gauge_addr, 1),\n",
    "        'dynamicBoost': dynamic_boosts.get(gauge_addr, 1),\n",
    "        'cap': f\"{cap_override_data.get(gauge_addr, VOTE_CAP_IN_PERCENT)}%\",\n",
    "        'withBonus': False\n",
    "    }\n",
    "\n",
    "\n",
    "# Spend unspent arb on the gauges that are not capped yet\n",
    "def recur_distribute_unspend_arb():\n",
    "    unspent_arb = ARBITRUM_TO_DISTRIBUTE - sum([gauge['distribution'] for gauge in arb_gauge_distributions.values()])\n",
    "    if unspent_arb > 0:\n",
    "        # Find out total voting weight of uncapped gauges and mark it as 100%:\n",
    "        total_uncapped_weight = sum(\n",
    "            [g['voteWeight'] for g in [\n",
    "                gauge for addr, gauge in arb_gauge_distributions.items() if gauge['distribution'] < VOTE_CAPS[addr]]\n",
    "             ]\n",
    "        )\n",
    "        # Iterate over uncapped gauges and distribute unspent arb proportionally to their voting weight which is total uncapped weight\n",
    "        for a, uncap_gauge in {addr: gauge for addr, gauge in arb_gauge_distributions.items() if\n",
    "                               gauge['distribution'] < VOTE_CAPS[addr]}.items():\n",
    "            # For each loop calculate unspend arb\n",
    "            unspent_arb = ARBITRUM_TO_DISTRIBUTE - sum(\n",
    "                [gauge['distribution'] for gauge in arb_gauge_distributions.values()])\n",
    "            # Don't distribute more than vote cap\n",
    "            distribution = min(\n",
    "                uncap_gauge['distribution'] + unspent_arb * uncap_gauge['voteWeight'] / total_uncapped_weight,\n",
    "                VOTE_CAPS[a])\n",
    "            uncap_gauge['distribution'] = distribution\n",
    "            uncap_gauge['%distribution'] = uncap_gauge['distribution'] / ARBITRUM_TO_DISTRIBUTE * 100\n",
    "    # Call recursively if there is still unspent arb\n",
    "    if ARBITRUM_TO_DISTRIBUTE - sum([g['distribution'] for g in arb_gauge_distributions.values()]) > 0:\n",
    "        recur_distribute_unspend_arb()\n",
    "\n",
    "\n",
    "recur_distribute_unspend_arb()\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Unspent arb: {ARBITRUM_TO_DISTRIBUTE - sum([gauge['distribution'] for gauge in arb_gauge_distributions.values()])}\")\n",
    "print(f\"Arb distributed: {sum([gauge['distribution'] for gauge in arb_gauge_distributions.values()])}\")\n",
    "# # Remove arb gauges with 0 distribution\n",
    "arb_gauge_distributions = {addr: gauge for addr, gauge in arb_gauge_distributions.items() if\n",
    "                           gauge['distribution'] > 0}\n",
    "# Toss in bonus arb to the predefined gauge:\n",
    "arb_gauge_distributions[ARB_ROOT_GAUGE]['distribution'] += ARBITRUM_TO_USD_POOL\n",
    "arb_gauge_distributions[ARB_ROOT_GAUGE]['withBonus'] = True\n",
    "arb_gauge_distributions_df = pd.DataFrame.from_dict(arb_gauge_distributions, orient='index')\n",
    "arb_gauge_distributions_df = arb_gauge_distributions_df.sort_values(by='%distribution', ascending=False)\n",
    "display(HTML(arb_gauge_distributions_df.to_html(index=False)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T17:31:48.565317Z",
     "start_time": "2023-09-11T17:31:43.053501Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export to json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "arb_gauge_distributions_df.to_csv('../output/arb_airdrop/arb_airdrop.csv', index=False)\n",
    "\n",
    "# Dump into output.json using:\n",
    "with open('../data/output_tx_template.json') as f:\n",
    "    output_data = json.load(f)\n",
    "\n",
    "# Find transaction with func name `setRecipientList` and dump gauge \n",
    "gauge_distributions = arb_gauge_distributions.values()\n",
    "assert sum([gauge['distribution'] for gauge in gauge_distributions]) == ARBITRUM_TO_DISTRIBUTE + ARBITRUM_TO_USD_POOL\n",
    "for tx in output_data['transactions']:\n",
    "    if tx['contractMethod']['name'] == 'setRecipientList':\n",
    "        # Inject list of gauges addresses:\n",
    "        tx['contractInputsValues'][\n",
    "            'gaugeAddresses'] = f\"[{','.join([gauge['recipientGaugeAddr'] for gauge in gauge_distributions])}]\"\n",
    "        # Inject vote weights:\n",
    "        tx['contractInputsValues']['amountsPerPeriod'] = f\"[{','.join([str(int(gauge['distribution'] * 1e18)) for gauge in gauge_distributions])}]\"\n",
    "        tx['contractInputsValues']['maxPeriods'] = f\"[{','.join(['2' for gauge in gauge_distributions])}]\"\n",
    "        break\n",
    "\n",
    "# Dump back to arb_distribution_for_msig.json\n",
    "with open('../output/arb_airdrop/arb_airdrop.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-11T17:31:48.569081Z",
     "start_time": "2023-09-11T17:31:48.564217Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
