{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch pool snapshots from balancer subgraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected data for dates: 2023-08-24 00:00:00 - 2023-09-07 00:00:00\n"
     ]
    }
   ],
   "source": [
    "from notebooks.airdrop_arb_distribution.config import POOLS_SNAPSHOTS_QUERY\n",
    "from notebooks.airdrop_arb_distribution.config import BALANCER_GRAPH_URL\n",
    "import json\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "\n",
    "from gql import Client\n",
    "from gql import gql\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "# Start date and end date are the following: start date is always previous Thursday 00:00 UTC, end date is always this Thursday 00:00 UTC:\n",
    "today = datetime.today()\n",
    "# Calculate days until previous Thursday (0 = Monday, 3 = Thursday)\n",
    "# Calculate days until thursday that was 2 weeks ago\n",
    "# days_until_thursday_two_weeks_ago = (today.weekday() - 3) % 7 + 7\n",
    "# # Calculate start date by subtracting days_until_previous_thursday and setting time to 00:00\n",
    "# start_date = today - timedelta(days=days_until_thursday_two_weeks_ago, hours=today.hour, minutes=today.minute,\n",
    "#                                seconds=today.second, microseconds=today.microsecond)\n",
    "# # Calculate end date by adding 7 days to the start date\n",
    "# end_date = start_date + timedelta(days=14)\n",
    "# 24 Aug 2023\n",
    "start_date = datetime(2023, 8, 24)\n",
    "end_date = start_date + timedelta(days=14)\n",
    "start_ts = int(start_date.timestamp())\n",
    "end_ts = int(end_date.timestamp())\n",
    "\n",
    "\n",
    "# Fetch all the data from the balancer subgraph\n",
    "def make_gql_client(url: str) -> Optional[Client]:\n",
    "    transport = RequestsHTTPTransport(url=url, retries=3)\n",
    "    return Client(\n",
    "        transport=transport, fetch_schema_from_transport=True, execute_timeout=60\n",
    "    )\n",
    "\n",
    "\n",
    "def get_balancer_pool_snapshots() -> Optional[List[Dict]]:\n",
    "    client = make_gql_client(BALANCER_GRAPH_URL)\n",
    "    all_pools = []\n",
    "    limit = 100\n",
    "    offset = 0\n",
    "    while True:\n",
    "        result = client.execute(\n",
    "            gql(POOLS_SNAPSHOTS_QUERY.format(first=limit, skip=offset, start_ts=start_ts, end_ts=end_ts)))\n",
    "        all_pools.extend(result['poolSnapshots'])\n",
    "        offset += limit\n",
    "        if len(result['poolSnapshots']) < limit - 1:\n",
    "            break\n",
    "    return all_pools\n",
    "\n",
    "\n",
    "pool_snapshots = get_balancer_pool_snapshots()\n",
    "\n",
    "print(f\"Collected data for dates: {start_date} - {end_date}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T11:14:13.059784Z",
     "start_time": "2023-09-13T11:14:05.792209Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate BAL emissions per week:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current BAL emissions per week: 121929.98021178861\n"
     ]
    }
   ],
   "source": [
    "from notebooks.airdrop_arb_distribution.config import CURRENT_YEAR\n",
    "\n",
    "emissions_per_week = 0\n",
    "with open('../../data/emissionsPerYear.json') as f:\n",
    "    data = json.load(f)\n",
    "for item in data['data']:\n",
    "    if item['year'] == str(CURRENT_YEAR):\n",
    "        emissions_per_week = float(item['balPerWeek'])\n",
    "        break\n",
    "print(f'Current BAL emissions per week: {emissions_per_week}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T11:14:13.062800Z",
     "start_time": "2023-09-13T11:14:13.057912Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-process all the data in this cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from notebooks.airdrop_arb_distribution.config import BALANCER_GAUGE_CONTROLLER_ABI\n",
    "from notebooks.airdrop_arb_distribution.config import BALANCER_GAUGE_CONTROLLER_ADDR\n",
    "from notebooks.airdrop_arb_distribution.config import ARB_CHAIN_ID\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from web3 import Web3\n",
    "from pycoingecko import CoinGeckoAPI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "web3 = Web3(Web3.HTTPProvider(os.environ[\"ETHNODEURL\"]))\n",
    "\n",
    "# fetch balancer token usd price:\n",
    "cg = CoinGeckoAPI()\n",
    "bal_token_price = cg.get_price(ids='balancer', vs_currencies='usd')['balancer']['usd']\n",
    "# Fetch all voting gauges from github json\n",
    "voting_gauges_req = requests.get(\n",
    "    \"https://raw.githubusercontent.com/balancer/frontend-v2/master/src/data/voting-gauges.json\")\n",
    "if not voting_gauges_req.ok:\n",
    "    raise ValueError(\"Failed to fetch voting gauges\")\n",
    "voting_gauges = voting_gauges_req.json()\n",
    "\n",
    "# Collect arb gauges\n",
    "arb_gauges = {}\n",
    "for gauge in voting_gauges:\n",
    "    # Only collect gauges for the arb chain and that are not killed\n",
    "    if int(gauge['network']) == ARB_CHAIN_ID and gauge['isKilled'] is False:\n",
    "        arb_gauges[gauge['address']] = {\n",
    "            'gaugeAddress': gauge['address'],\n",
    "            'pool': gauge['pool']['address'],\n",
    "            'symbol': gauge['pool']['symbol'],\n",
    "            'id': gauge['pool']['id'],\n",
    "        }\n",
    "\n",
    "gauge_c_contract = web3.eth.contract(address=BALANCER_GAUGE_CONTROLLER_ADDR, abi=BALANCER_GAUGE_CONTROLLER_ABI)\n",
    "\n",
    "boost_data = {}\n",
    "cap_override_data = {}\n",
    "# Before, load boost data from the file\n",
    "with open('../../data/arbitrumGrantGuageMetadata.json') as f:\n",
    "    boosties = json.load(f)\n",
    "    for boost in boosties:\n",
    "        boost_data[boost['gaugeAddress']] = boost.get('fixedBoost', 1)\n",
    "        cap_override_data[boost['gaugeAddress']] = boost.get('capOverride', 10)\n",
    "pool_protocol_fees = {}\n",
    "\n",
    "# Collect protocol fees from the pool snapshots:\n",
    "for gauge_addr, gauge_data in arb_gauges.items():\n",
    "    for pool_snapshot in pool_snapshots:\n",
    "        if Web3.to_checksum_address(pool_snapshot['pool']['address']) == Web3.to_checksum_address(gauge_data['pool']):\n",
    "            # Since snapshots are sorted by timestamp descending, we can just take the first one we find for each pool and break\n",
    "            protocol_fee = float(pool_snapshot['protocolFee']) if pool_snapshot['protocolFee'] else 0\n",
    "            pool_protocol_fees[gauge_addr] = protocol_fee\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T11:14:13.658208Z",
     "start_time": "2023-09-13T11:14:13.064941Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Apply boost data to arb gauges\n",
    "vote_weights = {}\n",
    "combined_boost = {}\n",
    "# Dynamic boost data to print out in the final table\n",
    "dynamic_boosts = {}\n",
    "# Collect gauge voting weights from the gauge controller on chain\n",
    "for gauge_addr, gauge_data in arb_gauges.items():\n",
    "    weight = gauge_c_contract.functions.gauge_relative_weight(gauge_addr).call() / 1e18 * 100\n",
    "    # Calculate dynamic boost. Formula is `[Fees earned/value of bal emitted per pool + 1]`\n",
    "    dollar_value_of_bal_emitted = weight * emissions_per_week * bal_token_price\n",
    "    if dollar_value_of_bal_emitted != 0:\n",
    "        dynamic_boost = (pool_protocol_fees.get(gauge_addr, 0) / dollar_value_of_bal_emitted) + 1\n",
    "    else:\n",
    "        dynamic_boost = 1\n",
    "    dynamic_boosts[gauge_addr] = dynamic_boost\n",
    "    # Now calculate the final boost value, which uses formula - (dynamic boost + fixed boost) - 1\n",
    "    boost = (dynamic_boost + boost_data.get(gauge_addr, 1)) - 1\n",
    "    combined_boost[gauge_addr] = boost\n",
    "    weight *= boost\n",
    "    vote_weights[gauge_addr] = weight\n",
    "    arb_gauges[gauge_addr]['voteWeight'] = weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T11:14:19.257599Z",
     "start_time": "2023-09-13T11:14:13.661563Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculate arbitrum distribution across gauges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspent arb: 0.0\n",
      "Arb distributed: 80000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>recipientGaugeAddr</th>\n      <th>pool</th>\n      <th>symbol</th>\n      <th>voteWeight</th>\n      <th>distribution</th>\n      <th>%distribution</th>\n      <th>boost</th>\n      <th>staticBoost</th>\n      <th>dynamicBoost</th>\n      <th>cap</th>\n      <th>bonus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0x2eB5661002b68EBE887d29d415c3A3b52536912C</td>\n      <td>0x4a2F6Ae7F3e5D715689530873ec35593Dc28951B</td>\n      <td>wstETH/rETH/cbETH</td>\n      <td>1.428668</td>\n      <td>16000.000000</td>\n      <td>20.000000</td>\n      <td>1.755340</td>\n      <td>1.75</td>\n      <td>1.005340</td>\n      <td>20%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0xd6B875d62c2661eaB66472F36c672e4B512f1135</td>\n      <td>0xadE4A71BB62bEc25154CFc7e6ff49A513B491E81</td>\n      <td>rETH-WETH-BPT</td>\n      <td>1.114417</td>\n      <td>13206.748736</td>\n      <td>16.508436</td>\n      <td>1.752078</td>\n      <td>1.75</td>\n      <td>1.002078</td>\n      <td>20%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0xcf9f895296F5e1D66a7D4dcf1d92e1B435E9f999</td>\n      <td>0x32dF62dc3aEd2cD6224193052Ce665DC18165841</td>\n      <td>RDNT-WETH</td>\n      <td>2.636144</td>\n      <td>8000.000000</td>\n      <td>10.000000</td>\n      <td>2.565307</td>\n      <td>1.50</td>\n      <td>2.065307</td>\n      <td>10%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0xd956246EA5b06DEa930F0A7feC1FFf000436e3f2</td>\n      <td>0x8bc65Eed474D1A00555825c91FeAb6A8255C2107</td>\n      <td>DOLA/USDC BPT</td>\n      <td>1.101371</td>\n      <td>8000.000000</td>\n      <td>10.000000</td>\n      <td>1.000523</td>\n      <td>1.00</td>\n      <td>1.000523</td>\n      <td>10%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0x82d2c7B67Eaa5028c89BE86CeA8e1DF5bd2119A1</td>\n      <td>0xc7FA3A3527435720f0e2a4c1378335324dd4F9b3</td>\n      <td>55auraBal-45wsteth</td>\n      <td>0.821157</td>\n      <td>8000.000000</td>\n      <td>10.000000</td>\n      <td>1.005280</td>\n      <td>1.00</td>\n      <td>1.005280</td>\n      <td>10%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0x260cbb867359a1084eC97de4157d06ca74e89415</td>\n      <td>0x9791d590788598535278552EEcD4b211bFc790CB</td>\n      <td>wstETH-WETH-BPT</td>\n      <td>0.597407</td>\n      <td>6613.777020</td>\n      <td>8.267221</td>\n      <td>1.765351</td>\n      <td>1.75</td>\n      <td>1.015351</td>\n      <td>20%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0xfC745035F31BCbaEb2D1a89aA9171495c671F6cE</td>\n      <td>0x3FD4954a851eaD144c2FF72B1f5a38Ea5976Bd54</td>\n      <td>ankrETH/wstETH-BPT</td>\n      <td>0.471499</td>\n      <td>6220.233198</td>\n      <td>7.775291</td>\n      <td>1.754860</td>\n      <td>1.75</td>\n      <td>1.004860</td>\n      <td>20%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0x011417BBED6FC9cefF36C032D431b0eFcBA7f8B3</td>\n      <td>0xc9f52540976385A84BF416903e1Ca3983c539E34</td>\n      <td>50tBTC-50WETH</td>\n      <td>0.424183</td>\n      <td>5909.478657</td>\n      <td>7.386848</td>\n      <td>1.009451</td>\n      <td>1.00</td>\n      <td>1.009451</td>\n      <td>10%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0xa14453084318277b11d38FbE05D857A4f647442B</td>\n      <td>0x423A1323c871aBC9d89EB06855bF5347048Fc4A5</td>\n      <td>4POOL-BPT</td>\n      <td>0.281785</td>\n      <td>13398.883093</td>\n      <td>4.248604</td>\n      <td>1.006157</td>\n      <td>1.00</td>\n      <td>1.006157</td>\n      <td>10%</td>\n      <td>10000</td>\n    </tr>\n    <tr>\n      <td>0xb438c6cc53315FfA3fcD1bc8b27d6c3155b0B56A</td>\n      <td>0x542F16DA0efB162D20bF4358EfA095B70A100f9E</td>\n      <td>2BTC</td>\n      <td>0.226369</td>\n      <td>3215.361135</td>\n      <td>4.019201</td>\n      <td>1.023530</td>\n      <td>1.00</td>\n      <td>1.023530</td>\n      <td>10%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0x04fc019017eD3F921D5ec11fFf84B870744BA0d1</td>\n      <td>0xa231aEa07Bb5e79aE162f95903806FC5AD65fF11</td>\n      <td>50DFX-50WETH</td>\n      <td>0.093369</td>\n      <td>1255.544995</td>\n      <td>1.569431</td>\n      <td>1.000169</td>\n      <td>1.00</td>\n      <td>1.000169</td>\n      <td>10%</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>0xeF767E740D83d410794519c2F93Db32e44359a5C</td>\n      <td>0xb3028Ca124B80CFE6E9CA57B70eF2F0CCC41eBd4</td>\n      <td>50MAGIC-50USDC</td>\n      <td>0.012657</td>\n      <td>179.973165</td>\n      <td>0.224966</td>\n      <td>690.881283</td>\n      <td>1.00</td>\n      <td>690.881283</td>\n      <td>10%</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebooks.airdrop_arb_distribution.config import ARBITRUM_TO_USD_POOL\n",
    "from notebooks.airdrop_arb_distribution.config import ARB_ROOT_GAUGE\n",
    "from notebooks.airdrop_arb_distribution.config import VOTE_CAP_IN_PERCENT\n",
    "from notebooks.airdrop_arb_distribution.config import ARBITRUM_TO_DISTRIBUTE\n",
    "from notebooks import get_abi\n",
    "from IPython.core.display import HTML\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Vote caps in percents are calculated as a percentage of the total amount of arb to distribute\n",
    "VOTE_CAPS_IN_PERCENTS = {gauge_addr: cap_override_data.get(gauge_addr, VOTE_CAP_IN_PERCENT) for gauge_addr in\n",
    "                         arb_gauges.keys()}\n",
    "# Custom gauge caps taken from boost data, calculated as a percentage of the total amount of arb to distribute\n",
    "VOTE_CAPS = {gauge_addr: VOTE_CAPS_IN_PERCENTS[gauge_addr] / 100 * ARBITRUM_TO_DISTRIBUTE for gauge_addr in\n",
    "             arb_gauges.keys()}\n",
    "\n",
    "# Calculate total weight\n",
    "total_weight = sum([gauge['voteWeight'] for gauge in arb_gauges.values()])\n",
    "arb_gauge_distributions = {\n",
    "\n",
    "}\n",
    "for gauge_addr, gauge_data in arb_gauges.items():\n",
    "    # Calculate distribution based on vote weight and total weight\n",
    "    to_distribute = ARBITRUM_TO_DISTRIBUTE * gauge_data['voteWeight'] / total_weight\n",
    "    # Cap distribution\n",
    "    to_distribute = to_distribute if to_distribute < VOTE_CAPS[gauge_addr] else VOTE_CAPS[gauge_addr]\n",
    "    # Get arb gauge addr\n",
    "    mainnet_arb_root_gauge_contract = web3.eth.contract(\n",
    "        address=Web3.to_checksum_address(gauge_addr),\n",
    "        abi=get_abi(\"ArbRootGauge\")\n",
    "    )\n",
    "    arb_gauge_distributions[gauge_addr] = {\n",
    "        # 'gaugeAddress': gauge_addr,\n",
    "        'recipientGaugeAddr': mainnet_arb_root_gauge_contract.functions.getRecipient().call(),\n",
    "        'pool': gauge_data['pool'],\n",
    "        'symbol': gauge_data['symbol'],\n",
    "        'voteWeight': gauge_data['voteWeight'],\n",
    "        'distribution': to_distribute if to_distribute < VOTE_CAPS[gauge_addr] else VOTE_CAPS[gauge_addr],\n",
    "        '%distribution': to_distribute / ARBITRUM_TO_DISTRIBUTE * 100,\n",
    "        'boost': combined_boost.get(gauge_addr, 1),\n",
    "        'staticBoost': boost_data.get(gauge_addr, 1),\n",
    "        'dynamicBoost': dynamic_boosts.get(gauge_addr, 1),\n",
    "        'cap': f\"{cap_override_data.get(gauge_addr, VOTE_CAP_IN_PERCENT)}%\",\n",
    "        'bonus': 0\n",
    "    }\n",
    "\n",
    "\n",
    "# Spend unspent arb on the gauges that are not capped yet\n",
    "def recur_distribute_unspend_arb():\n",
    "    unspent_arb = ARBITRUM_TO_DISTRIBUTE - sum([gauge['distribution'] for gauge in arb_gauge_distributions.values()])\n",
    "    if unspent_arb > 0:\n",
    "        # Find out total voting weight of uncapped gauges and mark it as 100%:\n",
    "        total_uncapped_weight = sum(\n",
    "            [g['voteWeight'] for g in [\n",
    "                gauge for addr, gauge in arb_gauge_distributions.items() if gauge['distribution'] < VOTE_CAPS[addr]]\n",
    "             ]\n",
    "        )\n",
    "        # Iterate over uncapped gauges and distribute unspent arb proportionally to their voting weight which is total uncapped weight\n",
    "        for a, uncap_gauge in {addr: gauge for addr, gauge in arb_gauge_distributions.items() if\n",
    "                               gauge['distribution'] < VOTE_CAPS[addr]}.items():\n",
    "            # For each loop calculate unspend arb\n",
    "            unspent_arb = ARBITRUM_TO_DISTRIBUTE - sum(\n",
    "                [gauge['distribution'] for gauge in arb_gauge_distributions.values()])\n",
    "            # Don't distribute more than vote cap\n",
    "            distribution = min(\n",
    "                uncap_gauge['distribution'] + unspent_arb * uncap_gauge['voteWeight'] / total_uncapped_weight,\n",
    "                VOTE_CAPS[a])\n",
    "            uncap_gauge['distribution'] = distribution\n",
    "            uncap_gauge['%distribution'] = uncap_gauge['distribution'] / ARBITRUM_TO_DISTRIBUTE * 100\n",
    "    # Call recursively if there is still unspent arb\n",
    "    if ARBITRUM_TO_DISTRIBUTE - sum([g['distribution'] for g in arb_gauge_distributions.values()]) > 0:\n",
    "        recur_distribute_unspend_arb()\n",
    "\n",
    "\n",
    "recur_distribute_unspend_arb()\n",
    "\n",
    "print(\n",
    "    f\"Unspent arb: {ARBITRUM_TO_DISTRIBUTE - sum([gauge['distribution'] for gauge in arb_gauge_distributions.values()])}\")\n",
    "print(f\"Arb distributed: {sum([gauge['distribution'] for gauge in arb_gauge_distributions.values()])}\")\n",
    "# # Remove arb gauges with 0 distribution\n",
    "arb_gauge_distributions = {addr: gauge for addr, gauge in arb_gauge_distributions.items() if\n",
    "                           gauge['distribution'] > 0}\n",
    "# Toss in bonus arb to the predefined gauge:\n",
    "arb_gauge_distributions[ARB_ROOT_GAUGE]['distribution'] += ARBITRUM_TO_USD_POOL\n",
    "arb_gauge_distributions[ARB_ROOT_GAUGE]['bonus'] = ARBITRUM_TO_USD_POOL\n",
    "arb_gauge_distributions_df = pd.DataFrame.from_dict(arb_gauge_distributions, orient='index')\n",
    "arb_gauge_distributions_df = arb_gauge_distributions_df.sort_values(by='%distribution', ascending=False)\n",
    "display(HTML(arb_gauge_distributions_df.to_html(index=False)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T11:20:23.308438Z",
     "start_time": "2023-09-13T11:20:17.561608Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export to json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89999.99999999999\n"
     ]
    }
   ],
   "source": [
    "# Export to csv\n",
    "arb_gauge_distributions_df.to_csv(f'./output/arb_airdrop_{start_date.date()}_{end_date.date()}.csv',\n",
    "                                  index=False)\n",
    "\n",
    "# Dump into output.json using:\n",
    "with open('../../data/output_tx_template.json') as f:\n",
    "    output_data = json.load(f)\n",
    "\n",
    "# Find transaction with func name `setRecipientList` and dump gauge \n",
    "gauge_distributions = arb_gauge_distributions.values()\n",
    "assert round(\n",
    "    sum([gauge['distribution'] for gauge in gauge_distributions]), 2) == ARBITRUM_TO_DISTRIBUTE + ARBITRUM_TO_USD_POOL\n",
    "for tx in output_data['transactions']:\n",
    "    if tx['contractMethod']['name'] == 'setRecipientList':\n",
    "        # Inject list of gauges addresses:\n",
    "        tx['contractInputsValues'][\n",
    "            'gaugeAddresses'] = f\"[{','.join([gauge['recipientGaugeAddr'] for gauge in gauge_distributions])}]\"\n",
    "        # Inject vote weights:\n",
    "        tx['contractInputsValues'][\n",
    "            'amountsPerPeriod'] = f\"[{','.join([str(int(gauge['distribution'] * 1e18)) for gauge in gauge_distributions])}]\"\n",
    "        tx['contractInputsValues']['maxPeriods'] = f\"[{','.join(['2' for gauge in gauge_distributions])}]\"\n",
    "        break\n",
    "\n",
    "# Dump back to arb_distribution_for_msig.json\n",
    "with open(f'./output/arb_airdrop_{start_date.date()}_{end_date.date()}.json', 'w') as f:\n",
    "    json.dump(output_data, f, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T11:17:13.605805Z",
     "start_time": "2023-09-13T11:17:13.586041Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
