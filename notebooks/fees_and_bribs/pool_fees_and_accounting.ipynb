{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Collecting protocol fees across Balancer core pools on all networks\n",
    "- Spreadsheet as reference: https://docs.google.com/spreadsheets/d/1xwUPpbYq7woVOU9vQ8EB8MY75I-1mauTLyDVwvKUDKo/edit#gid=0\n",
    "- Collab: https://colab.research.google.com/drive/1vKCvcV5mkL1zwW3565kLSGkBEbt8NsoB?usp=sharing\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e739385af75b2478"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bpt prices for polygon\n",
      "Collecting bpt prices for mainnet\n",
      "Collecting bpt prices for arbitrum\n",
      "Collecting bpt prices for optimism\n",
      "Collecting bpt prices for gnosis\n",
      "Collecting bpt prices for zkevm\n",
      "Collecting bpt prices for avalanche\n",
      "Collecting bpt prices for base\n",
      "{'0xf0ad209e2e969eaaa8c882aac71f02d8a047d5c2000200000000000000000b49': Decimal('0.5280424513237304447412142192'), '0xee278d943584dd8640eaf4cc6c7a5c80c0073e85000200000000000000000bc7': Decimal('0.5258587006211421026950010597'), '0x93d199263632a4ef4bb438f1feb99e57b4b5f0bd0000000000000000000005c2': Decimal('1615.639222768882312511327769'), '0x1e19cf2d73a72ef1332c882f20534b6519be0276000200000000000000000112': Decimal('1655.742499099692472457334460'), '0xe7e2c68d3b13d905bbb636709cf4dfd21076b9d20000000000000000000005ca': Decimal('1583.635774961356404658467626'), '0xf7a826d47c8e02835d94fb0aa40f0cc9505cb1340002000000000000000005e0': Decimal('1612.932033705533336612464332'), '0xf16aee6a71af1a9bc8f56975a4c2705ca7a782bc0002000000000000000004bb': Decimal('27.42670529040436556407878377'), '0xb08885e6026bab4333a80024ec25a1a3e1ff2b8a000200000000000000000445': Decimal('1628.179323995485920040465830'), '0x8353157092ed8be69a9df8f95af097bbf33cb2af0000000000000000000005d9': Decimal('0.9859060183112129756703350925'), '0xdfe6e7e18f6cc65fa13c8d8966013d4fda74b6ba000000000000000000000558': Decimal('1624.417064045334707520668011'), '0x5f1f4e50ba51d723f12385a8a9606afc3a0555f5000200000000000000000465': Decimal('52.64102050690129483399720160'), '0x1ee442b5326009bb18f2f472d3e0061513d1a0ff000200000000000000000464': Decimal('59.74950982281294474295941968'), '0x9f9d900462492d4c21e9523ca95a7cd86142f298000200000000000000000462': Decimal('195.7152669350317574107275624'), '0x3ff3a210e57cfe679d9ad1e9ba6453a716c56a2e0002000000000000000005d5': Decimal('0.6775718669445422070842815628'), '0xf01b0684c98cd7ada480bfdf6e43876422fa1fc10002000000000000000005de': Decimal('1614.461477259506788372003730'), '0x36be1e97ea98ab43b4debf92742517266f5731a3000200000000000000000466': Decimal('9.838588171206903184872507231'), '0xade4a71bb62bec25154cfc7e6ff49a513b491e81000000000000000000000497': Decimal('1615.672745967866487419447586'), '0x9791d590788598535278552eecd4b211bfc790cb000000000000000000000498': Decimal('1616.037918790086298584847046'), '0x4a2f6ae7f3e5d715689530873ec35593dc28951b000000000000000000000481': Decimal('1619.269923863553646145555472'), '0x423a1323c871abc9d89eb06855bf5347048fc4a5000000000000000000000496': Decimal('1.000576626335701219563759938'), '0x32df62dc3aed2cd6224193052ce665dc181658410002000000000000000003bd': Decimal('1.091606488246363625882522052'), '0x0c8972437a38b389ec83d1e666b69b8a4fcf8bfd00000000000000000000049e': Decimal('1615.916961604586030248042031'), '0xfd2620c9cfcec7d152467633b3b0ca338d3d78cc00000000000000000000001c': Decimal('9.064269564714044471080538294'), '0xc13546b97b9b1b15372368dc06529d7191081f5b00000000000000000000001d': Decimal('9.104841229820183873142857187'), '0x9fa6ab3d78984a69e712730a2227f20bcc8b5ad900000000000000000000001f': Decimal('9.086156449325848684656555495'), '0xb26f0e66317846bd5fe0cbaa1d269f0efeb05c9600000000000000000000001e': Decimal('1.000176242157305632470118383'), '0x55bec22f8f6c69137ceaf284d9b441db1b9bfedc000200000000000000000011': Decimal('0.9641427832597667561166663122'), '0xfb4c2e6e6e27b5b4a07a36360c89ede29bb3c9b6000000000000000000000026': Decimal('1613.300351379435566566568616'), '0xc771c1a5905420daec317b154eb13e4198ba97d0000000000000000000000023': Decimal('1616.176038830145192809059997'), '0x0c659734f1eef9c63b7ebdf78a164cdd745586db000000000000000000000046': Decimal('1.000797662078297939067737354')}\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from web3 import Web3\n",
    "\n",
    "from notebooks import get_block_by_ts\n",
    "from notebooks import get_twap_bpt_price\n",
    "from config_file import CORE_POOLS\n",
    "from config_file import Chains\n",
    "from config_file import web3_instances\n",
    "\n",
    "TARGET_BLOCKS = {}\n",
    "# ARBITRUM\n",
    "timestamp_now = 1695952610\n",
    "timestamp_2_weeks_ago = timestamp_now - (2 * 7 * 24 * 60 * 60)\n",
    "datetime_now = datetime.datetime.fromtimestamp(timestamp_now)\n",
    "datetime_2_weeks_ago = datetime.datetime.fromtimestamp(timestamp_2_weeks_ago)\n",
    "\n",
    "arb_block = get_block_by_ts(timestamp_now, \"arbitrum\")  # 18 August 2023\n",
    "TARGET_BLOCKS[Chains.ARBITRUM.value] = arb_block\n",
    "# Given Arb block time, we want to look back 2 weeks:\n",
    "arb_block_2_weeks_ago = get_block_by_ts(timestamp_2_weeks_ago, \"arbitrum\")\n",
    "# MAINNET\n",
    "mainnet_block = get_block_by_ts(timestamp_now, \"mainnet\")\n",
    "TARGET_BLOCKS[Chains.MAINNET.value] = mainnet_block\n",
    "# Given mainnet block time, we want to look back 2 weeks:\n",
    "mainnet_block_2_weeks_ago = get_block_by_ts(timestamp_2_weeks_ago, \"mainnet\")\n",
    "# BASE\n",
    "base_block = get_block_by_ts(timestamp_now, \"base\")\n",
    "TARGET_BLOCKS[Chains.BASE.value] = base_block\n",
    "# Given base block time, we want to look back 2 weeks:\n",
    "base_block_2_weeks_ago = get_block_by_ts(timestamp_2_weeks_ago, \"base\")\n",
    "\n",
    "# POLYGON\n",
    "poly_block = get_block_by_ts(timestamp_now, \"polygon\")\n",
    "TARGET_BLOCKS[Chains.POLYGON.value] = poly_block\n",
    "# Given polygon block time, we want to look back 2 weeks:\n",
    "poly_block_2_weeks_ago = get_block_by_ts(timestamp_2_weeks_ago, \"polygon\")\n",
    "\n",
    "# GNOSIS\n",
    "gnosis_block = get_block_by_ts(timestamp_now, \"gnosis\")\n",
    "TARGET_BLOCKS[Chains.GNOSIS.value] = gnosis_block\n",
    "# Given gnosis block time, we want to look back 2 weeks:\n",
    "gnosis_block_2_weeks_ago = get_block_by_ts(timestamp_2_weeks_ago, \"gnosis\")\n",
    "\n",
    "# Avalanche\n",
    "avax_block = get_block_by_ts(timestamp_now, \"avalanche\")\n",
    "TARGET_BLOCKS[Chains.AVALANCHE.value] = avax_block\n",
    "# Given avalanche block time, we want to look back 2 weeks:\n",
    "avax_block_2_weeks_ago = get_block_by_ts(timestamp_2_weeks_ago, \"avalanche\")\n",
    "\n",
    "bpt_twap_prices = {}\n",
    "gnosis_bpt_twap_prices = {}\n",
    "for chain in Chains:\n",
    "    print(f\"Collecting bpt prices for {chain.value}\")\n",
    "    pools = CORE_POOLS.get(chain.value, None)\n",
    "    if pools is None:\n",
    "        continue\n",
    "    for core_pool in pools:\n",
    "        bpt_twap_prices[core_pool] = get_twap_bpt_price(\n",
    "            core_pool, chain.value, getattr(web3_instances, chain.value), start_date=datetime.datetime.fromtimestamp(timestamp_now), block_number=TARGET_BLOCKS[chain.value]\n",
    "        )\n",
    "print(bpt_twap_prices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T12:43:23.428440Z",
     "start_time": "2023-10-09T12:40:25.509635Z"
    }
   },
   "id": "39d87004addaae1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetching data from the Balancer subgraphs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cde5ffca807e3849"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks import get_balancer_pool_snapshots\n",
    "from notebooks.fees_and_bribs.constants import BASE_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import POLYGON_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import ARB_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import MAINNET_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import GNOSIS_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import AVALANCHE_BALANCER_GRAPH_URL\n",
    "from typing import Dict\n",
    "\n",
    "arbi_pool_snapshots_now = get_balancer_pool_snapshots(arb_block, ARB_BALANCER_GRAPH_URL)\n",
    "arbi_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(arb_block_2_weeks_ago), ARB_BALANCER_GRAPH_URL)\n",
    "\n",
    "mainnet_pool_snapshots_now = get_balancer_pool_snapshots(mainnet_block, MAINNET_BALANCER_GRAPH_URL)\n",
    "mainnet_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(mainnet_block_2_weeks_ago),\n",
    "                                                                 MAINNET_BALANCER_GRAPH_URL)\n",
    "\n",
    "polygon_pool_snapshots_now = get_balancer_pool_snapshots(poly_block, POLYGON_BALANCER_GRAPH_URL)\n",
    "polygon_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(poly_block_2_weeks_ago),\n",
    "                                                                 POLYGON_BALANCER_GRAPH_URL)\n",
    "\n",
    "base_pool_snapshots_now = get_balancer_pool_snapshots(base_block, BASE_BALANCER_GRAPH_URL)\n",
    "base_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(base_block_2_weeks_ago),\n",
    "                                                              BASE_BALANCER_GRAPH_URL)\n",
    "\n",
    "gnosis_pool_snapshots_now = get_balancer_pool_snapshots(gnosis_block, GNOSIS_BALANCER_GRAPH_URL)\n",
    "gnosis_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(gnosis_block_2_weeks_ago),\n",
    "                                                                GNOSIS_BALANCER_GRAPH_URL)\n",
    "\n",
    "avax_pool_snapshots_now = get_balancer_pool_snapshots(avax_block, AVALANCHE_BALANCER_GRAPH_URL)\n",
    "avax_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(avax_block_2_weeks_ago),\n",
    "                                                              AVALANCHE_BALANCER_GRAPH_URL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T11:43:42.051458Z"
    }
   },
   "id": "e1e0b8b90f62234c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract fee data for CORE pools:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5333a7de445454d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from decimal import Decimal\n",
    "from notebooks import fetch_token_price_balgql\n",
    "\n",
    "\n",
    "def collect_fee_info(pools: list[str], chain: str, pools_now: list[dict], pools_shifted: list[dict],\n",
    "                     start_date: datetime.datetime) -> tuple[dict, dict]:\n",
    "    # Iterate through snapshots now and 2 weeks ago and extract fee data, by subtracting today's fee data from 2 weeks ago\n",
    "    # and then summing across all pools\n",
    "    fees = {}\n",
    "    token_fees = defaultdict(list)\n",
    "    for pool in pools:\n",
    "        current_fees_snapshots = [x for x in pools_now if x['pool']['id'] == pool]\n",
    "        current_fees_snapshots.sort(key=lambda x: x['timestamp'], reverse=True)\n",
    "        fees_2_weeks_ago = [x for x in pools_shifted if x['pool']['id'] == pool]\n",
    "        fees_2_weeks_ago.sort(key=lambda x: x['timestamp'], reverse=True)\n",
    "        # Take first element of list, which is the most recent snapshot\n",
    "        if not current_fees_snapshots or not fees_2_weeks_ago:\n",
    "            continue\n",
    "        pool_snapshot_now = current_fees_snapshots[0]\n",
    "        pool_snapshot_2_weeks_ago = fees_2_weeks_ago[0]\n",
    "        # Calculate fees\n",
    "        pool_fee = float(pool_snapshot_now['protocolFee']) - float(pool_snapshot_2_weeks_ago['protocolFee'])\n",
    "        pool_swap_fee = float(pool_snapshot_now['swapFees']) - float(pool_snapshot_2_weeks_ago['swapFees'])\n",
    "        # Now we need to collect token fee info. Let's start with BPT tokens, which is Balancer pool token. Notice,\n",
    "        # That totalProtocolFeePaidInBPT can be null, so we need to check for that\n",
    "        bpt_token_fee = 0\n",
    "        bpt_price_usd = bpt_twap_prices[chain][pool]\n",
    "        if bpt_price_usd is None:\n",
    "            bpt_price_usd = 0\n",
    "        if pool_snapshot_now['pool']['totalProtocolFeePaidInBPT'] is not None and pool_snapshot_2_weeks_ago['pool'][\n",
    "            'totalProtocolFeePaidInBPT'] is not None:\n",
    "            bpt_token_fee = float(pool_snapshot_now['pool']['totalProtocolFeePaidInBPT']) - float(\n",
    "                pool_snapshot_2_weeks_ago['pool']['totalProtocolFeePaidInBPT'])\n",
    "            token_fees[pool_snapshot_now['pool']['id']].append({\n",
    "                'symbol': pool_snapshot_now['pool']['symbol'],\n",
    "                'token': pool_snapshot_now['pool']['symbol'],\n",
    "                'token_fee': bpt_token_fee,\n",
    "                'token_price': bpt_price_usd,\n",
    "                'token_fee_in_usd': Decimal(bpt_token_fee) * bpt_price_usd,\n",
    "                'token_addr': pool_snapshot_now['pool']['address'],\n",
    "                'time_from': datetime_2_weeks_ago,\n",
    "                'time_to': datetime_now,\n",
    "                'chain': chain,\n",
    "            })\n",
    "        # Now collect fee info about fees paid in pool tokens. Pool tokens fee info is in pool.tokens dictionary. This will be separate dictionary\n",
    "        else:\n",
    "            bpt_price_usd = 0\n",
    "            for token_data in pool_snapshot_now['pool']['tokens']:\n",
    "                token_data_2_weeks_ago = \\\n",
    "                    [t for t in pool_snapshot_2_weeks_ago['pool']['tokens'] if t['address'] == token_data['address']][0]\n",
    "                token_fee = float(token_data.get('paidProtocolFees', None)) - float(\n",
    "                    token_data_2_weeks_ago.get('paidProtocolFees', None))\n",
    "                # Get twap token price from CoinGecko\n",
    "                token_price = fetch_token_price_balgql(token_data['address'], chain, start_date) or 0\n",
    "                token_fees[pool_snapshot_now['pool']['id']].append({\n",
    "                    'symbol': pool_snapshot_now['pool']['symbol'],\n",
    "                    'token': token_data['symbol'],\n",
    "                    'token_fee': token_fee,\n",
    "                    'token_price': token_price,\n",
    "                    'token_fee_in_usd': Decimal(token_fee) * token_price if token_price is not None else 0,\n",
    "                    'token_addr': token_data['address'],\n",
    "                    'time_from': datetime_2_weeks_ago,\n",
    "                    'time_to': datetime_now,\n",
    "                    'chain': chain,\n",
    "                })\n",
    "        # Calculate non-BPT fees in USD\n",
    "        fees[pool_snapshot_now['pool']['id']] = {\n",
    "            'symbol': pool_snapshot_now['pool']['symbol'],\n",
    "            'pool_fee': round(pool_fee, 2),\n",
    "            'swap_fee': round(pool_swap_fee, 2),\n",
    "            'bpt_token_fee': round(bpt_token_fee, 2),\n",
    "            # Get fee in USD by multiplying bpt_token_fee by price of BPT token taken from twap_bpt_price\n",
    "            'bpt_token_fee_in_usd': round(Decimal(bpt_token_fee) * bpt_price_usd, 2),\n",
    "            'token_fees_in_usd': round(sum([x['token_fee_in_usd'] for x in\n",
    "                                            token_fees[\n",
    "                                                pool_snapshot_now['pool']['symbol']]]) if bpt_price_usd == 0 else 0, 2),\n",
    "            'time_from': datetime_2_weeks_ago,\n",
    "            'time_to': datetime_now,\n",
    "            'chain': chain,\n",
    "            'token_fees': token_fees[pool_snapshot_now['pool']['symbol']],\n",
    "            'pool_addr': pool_snapshot_now['pool']['address'],\n",
    "        }\n",
    "    return fees\n",
    "\n",
    "\n",
    "arb_fees = collect_fee_info(CORE_POOLS.arbitrum, 'arbitrum', arbi_pool_snapshots_now,\n",
    "                            arbi_pool_snapshots_2_weeks_ago, datetime_now)\n",
    "mainnet_fees = collect_fee_info(CORE_POOLS.mainnet, 'mainnet', mainnet_pool_snapshots_now,\n",
    "                                mainnet_pool_snapshots_2_weeks_ago, datetime_now)\n",
    "polygon_fees = collect_fee_info(CORE_POOLS.polygon, 'polygon', polygon_pool_snapshots_now,\n",
    "                                polygon_pool_snapshots_2_weeks_ago, datetime_now)\n",
    "base_fees = collect_fee_info(CORE_POOLS.base, 'base', base_pool_snapshots_now, base_pool_snapshots_2_weeks_ago,\n",
    "                             datetime_now)\n",
    "# gnosis_fees = collect_fee_info(CORE_POOLS.gnosis, 'gnosis', gnosis_pool_snapshots_now,\n",
    "#                                gnosis_pool_snapshots_2_weeks_ago, gnosis_datetime_now)\n",
    "avax_fees = collect_fee_info(CORE_POOLS.avalanche, 'avalanche', avax_pool_snapshots_now,\n",
    "                             avax_pool_snapshots_2_weeks_ago, datetime_now)\n",
    "# Convert to dataframe, sort by chain and pool fee\n",
    "joint_fees = {**arb_fees, **mainnet_fees, **polygon_fees, **base_fees, **avax_fees}\n",
    "joint_fees_df = pd.DataFrame.from_dict(joint_fees, orient='index')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T11:43:42.052537Z",
     "start_time": "2023-10-09T11:43:42.052203Z"
    }
   },
   "id": "e79b2f6a4ead2cad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove `token_fees` field from dataframe, as it's too big\n",
    "joint_fees_df_copy = joint_fees_df.drop(columns=['token_fees'])\n",
    "# Display all rows in dataframe\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "joint_fees_df_copy.sort_values(by=['chain', 'pool_fee'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T11:43:42.054084Z"
    }
   },
   "id": "52fccc19e5e6b4f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's calculate bribes paid to the pools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97a5370819f28ffc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks import calculate_aura_vebal_share\n",
    "\n",
    "aura_vebal_share = calculate_aura_vebal_share(web3_instances.mainnet, mainnet_block)\n",
    "\n",
    "# Bribes are split per chain and per pool, with each pool getting a share of the bribe proportional to its share of fees\n",
    "# paid by all pools on that chain. For example, if pool A paid 10% of all fees on Arbitrum, it will get 10% of the bribes. That 10% will be distributed between aura and vebal, proportional to their share of the bribe.\n",
    "FEE = Decimal(0.5)  # 50% goes to fees\n",
    "\n",
    "\n",
    "# Let's calculate share of fees paid by each pool on each chain\n",
    "def calc_and_split_bribes(fees: Dict, chain: str, fees_to_distribute: Decimal) -> Dict[str, Dict]:\n",
    "    pool_bribs = {}\n",
    "    # Calculate pool share in fees\n",
    "    total_fees = sum([data['pool_fee'] for pool, data in fees.items()])\n",
    "    for pool, data in fees.items():\n",
    "        pool_fees = data['bpt_token_fee_in_usd'] + data['token_fees_in_usd']\n",
    "        pool_share = pool_fees / Decimal(total_fees)\n",
    "        # If aura bribes is less than 500 USDC, we pay all bribes to balancer\n",
    "        aura_bribes = round(pool_share * fees_to_distribute * aura_vebal_share * FEE, 2)\n",
    "        if aura_bribes <= Decimal(500):\n",
    "            aura_bribes = Decimal(0)\n",
    "            bal_bribes = round(pool_share * fees_to_distribute * FEE, 2)\n",
    "        else:\n",
    "            bal_bribes = round(pool_share * fees_to_distribute * (1 - aura_vebal_share) * FEE, 2)\n",
    "        # Split fees between aura and bal fees\n",
    "        pool_bribs[pool] = {\n",
    "            \"symbol\": data['symbol'],\n",
    "            \"chain\": chain,\n",
    "            \"aura_bribes\": aura_bribes,\n",
    "            \"bal_bribes\": bal_bribes,\n",
    "            \"protocol_fees_collected\": pool_fees,\n",
    "            \"pool_addr\": data['pool_addr'],\n",
    "        }\n",
    "    return pool_bribs\n",
    "\n",
    "\n",
    "# TODO: Move to constants\n",
    "mainnet_bribes = calc_and_split_bribes(mainnet_fees, 'mainnet', Decimal(112945.77))\n",
    "arb_bribes = calc_and_split_bribes(arb_fees, 'arbitrum', Decimal(39481.82))\n",
    "polygon_bribes = calc_and_split_bribes(polygon_fees, 'polygon', Decimal(6592.87))\n",
    "base_bribes = calc_and_split_bribes(base_fees, 'base', Decimal(10260.35))\n",
    "# gnosis_bribes = calc_and_split_bribes(gnosis_fees, 'gnosis', Decimal(2503.21))\n",
    "# avax_bribes = calc_and_split_bribes(avax_fees, 'avalanche', Decimal(10297))\n",
    "# Convert to dataframe\n",
    "# joint_bribes_data = {**arb_bribes, **mainnet_bribes, **polygon_bribes, **base_bribes, **gnosis_bribes, **avax_bribes}\n",
    "joint_bribes_data = {**arb_bribes, **mainnet_bribes, **polygon_bribes, **base_bribes}\n",
    "# Sort by chain:\n",
    "joint_bribes_data = {k: v for k, v in sorted(joint_bribes_data.items(), key=lambda item: item[1]['chain'])}\n",
    "joint_bribes_df = pd.DataFrame.from_dict(joint_bribes_data, orient='index')\n",
    "# Sort by chain\n",
    "# Dump into csv and prefix with dates\n",
    "joint_bribes_df.to_csv(f'./output/bribes_{datetime_2_weeks_ago.date()}_{datetime_now.date()}.csv')\n",
    "joint_bribes_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T11:43:42.055810Z"
    }
   },
   "id": "efdef306c522076a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks import fetch_all_pools_info\n",
    "\n",
    "mainnet_pools_info = fetch_all_pools_info('mainnet')\n",
    "arb_pools_info = fetch_all_pools_info('arbitrum')\n",
    "polygon_pools_info = fetch_all_pools_info('polygon')\n",
    "base_pools_info = fetch_all_pools_info('base')\n",
    "gnosis_pools_info = fetch_all_pools_info('gnosis')\n",
    "avax_pools_info = fetch_all_pools_info('avalanche')\n",
    "\n",
    "mainnet_gauges = {pool_info['address']: Web3.to_checksum_address(pool_info['gauge']['address']) for pool_info in\n",
    "                  mainnet_pools_info}\n",
    "arb_gauges = {pool_info['address']: Web3.to_checksum_address(pool_info['gauge']['address']) for pool_info in\n",
    "              arb_pools_info}\n",
    "polygon_gauges = {pool_info['address']: Web3.to_checksum_address(pool_info['gauge']['address']) for pool_info in\n",
    "                  polygon_pools_info}\n",
    "base_gauges = {pool_info['address']: Web3.to_checksum_address(pool_info['gauge']['address']) for pool_info in\n",
    "               base_pools_info}\n",
    "gnosis_gauges = {pool_info['address']: Web3.to_checksum_address(pool_info['gauge']['address']) for pool_info in\n",
    "                 gnosis_pools_info}\n",
    "avax_gauges = {pool_info['address']: Web3.to_checksum_address(pool_info['gauge']['address']) for pool_info in\n",
    "               avax_pools_info}\n",
    "# Put it all into mapping per chain:\n",
    "mapped_gauges = {\n",
    "    'mainnet': mainnet_gauges,\n",
    "    'arbitrum': arb_gauges,\n",
    "    'polygon': polygon_gauges,\n",
    "    'base': base_gauges,\n",
    "    'gnosis': gnosis_gauges,\n",
    "    'avalanche': avax_gauges,\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-09T11:43:42.057180Z",
     "start_time": "2023-10-09T11:43:42.057114Z"
    }
   },
   "id": "93d3b07a2ccb9a32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load csv sheet to compare with the data collected above:\n",
    "bribes_df = pd.read_csv('compare_sheet.csv')\n",
    "# To dict:\n",
    "bribes_to_compare = bribes_df.to_dict(orient='records')\n",
    "# Each dict in list needs target to be Web3.toChecksumAddress\n",
    "bribes_csv_checksummed = []\n",
    "for bribe in bribes_to_compare:\n",
    "    bribes_csv_checksummed.append({\n",
    "        'target': Web3.to_checksum_address(bribe['target']),\n",
    "        'platform': bribe['platform'],\n",
    "        'amount': bribe['amount'],\n",
    "    })\n",
    "# These are bribes paid de-facto, so we need to convert them to the same format as we have in our data\n",
    "bribes_final_csv = {}\n",
    "for bribe in bribes_csv_checksummed:\n",
    "    if bribe['target'] not in bribes_final_csv:\n",
    "        bribes_final_csv[bribe['target']] = {}\n",
    "    bribes_final_csv[bribe['target']][bribe['platform']] = Decimal(bribe['amount'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T11:43:42.058037Z"
    }
   },
   "id": "533bf5074506799f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compare data from the sheet with the data we collected\n",
    "What does table below represent:\n",
    "- aura_automated_bribe: bribes paid to aura per pool calculated in this notebook\n",
    "- aura_actual_bribe: actual bribes paid to aura per pool from the sheet\n",
    "- aura_bribe_delta: difference between aura_automated_bribe and aura_actual_bribe\n",
    "- aura_bribe_delta_%: difference between aura_automated_bribe and aura_actual_bribe in %\n",
    "\n",
    "Same thing for balancer side:\n",
    "- bal_automated_bribe: bribes paid to balancer per pool calculated in this notebook\n",
    "- bal_actual_bribe: actual bribes paid to balancer per pool from the sheet\n",
    "- bal_bribe_delta: difference between bal_automated_bribe and bal_actual_bribe\n",
    "- bal_bribe_delta_%: difference between bal_automated_bribe and bal_actual_bribe in %"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab029ab946741672"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now we need to compare the data we collected with the data from the sheet\n",
    "# We need to compare bribes paid to each pool\n",
    "joint_bribes_dict = joint_bribes_df.to_dict(orient='records')\n",
    "bribes_delta = {}\n",
    "for gauge, data in bribes_final_csv.items():\n",
    "    for automated_bribe in joint_bribes_dict:\n",
    "        filtered_gauges = mapped_gauges[automated_bribe['chain']]\n",
    "        # If this condition is true, we can compare the bribes\n",
    "        if filtered_gauges[automated_bribe['pool_addr']] == gauge:\n",
    "            # Calculate delta between automated bribes and bribes from the sheet\n",
    "            # Calculate delta between automated_bribe['aura_bribes'] and data['aura'] in %\n",
    "            if automated_bribe['aura_bribes'] > data['aura']:\n",
    "                aura_bribe_delta = automated_bribe['aura_bribes'] - data['aura']\n",
    "                aura_bribe_delta_pct = (automated_bribe['aura_bribes'] - data['aura']) / data['aura'] * 100 if \\\n",
    "                    data['aura'] != 0 else 0\n",
    "            else:\n",
    "                aura_bribe_delta = data['aura'] - automated_bribe['aura_bribes']\n",
    "                aura_bribe_delta_pct = (data['aura'] - automated_bribe['aura_bribes']) / data['aura'] * 100 if \\\n",
    "                    data['aura'] != 0 else 0\n",
    "            if automated_bribe['bal_bribes'] > data['balancer']:\n",
    "                bal_bribe_delta = automated_bribe['bal_bribes'] - data['balancer']\n",
    "                bal_bribe_delta_pct = (automated_bribe['bal_bribes'] - data['balancer']) / data['balancer'] * 100 if \\\n",
    "                    data['balancer'] != 0 else 0\n",
    "            else:\n",
    "                bal_bribe_delta = data['balancer'] - automated_bribe['bal_bribes']\n",
    "                bal_bribe_delta_pct = (data['balancer'] - automated_bribe['bal_bribes']) / data['balancer'] * 100 if \\\n",
    "                    data['balancer'] != 0 else 0\n",
    "            bribes_delta[gauge] = {\n",
    "                'symbol': automated_bribe['symbol'],\n",
    "                'chain': automated_bribe['chain'],\n",
    "                'aura_automated_bribe': automated_bribe['aura_bribes'],\n",
    "                'aura_actual_bribe': round(data['aura'], 2),\n",
    "                'aura_bribe_delta': round(aura_bribe_delta, 2),\n",
    "                'aura_bribe_delta_%': f'{round(aura_bribe_delta_pct, 2)}%',\n",
    "                'bal_automated_bribe': automated_bribe['bal_bribes'],\n",
    "                'bal_actual_bribe': round(data['balancer'], 2),\n",
    "                'bal_bribe_delta': round(bal_bribe_delta, 2),\n",
    "                'bal_bribe_delta_%': f'{round(bal_bribe_delta_pct, 2)}%',\n",
    "            }\n",
    "# To df and print out without index:\n",
    "bribes_delta_df = pd.DataFrame.from_dict(bribes_delta, orient='index')\n",
    "bribes_delta_df.sort_values(by=['chain', 'aura_bribe_delta'], ascending=False)\n",
    "# Also dump to csv\n",
    "bribes_delta_df.to_csv(f'./output/bribes_delta_{datetime_2_weeks_ago.date()}_{datetime_now.date()}.csv')\n",
    "bribes_delta_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-09T11:43:42.058953Z"
    }
   },
   "id": "17f47521561f3499"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
