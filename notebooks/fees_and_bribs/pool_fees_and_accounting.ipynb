{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Collecting protocol fees across Balancer core pools on all networks\n",
    "- Spreadsheet as reference: https://docs.google.com/spreadsheets/d/1xwUPpbYq7woVOU9vQ8EB8MY75I-1mauTLyDVwvKUDKo/edit#gid=0\n",
    "- Collab: https://colab.research.google.com/drive/1vKCvcV5mkL1zwW3565kLSGkBEbt8NsoB?usp=sharing\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e739385af75b2478"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from web3 import Web3\n",
    "from web3.middleware import geth_poa_middleware\n",
    "\n",
    "from notebooks import get_block_by_ts\n",
    "from notebooks import get_twap_bpt_price\n",
    "from notebooks.fees_and_bribs.constants import ARB_CORE_POOLS\n",
    "from notebooks.fees_and_bribs.constants import BASE_CORE_POOLS\n",
    "from notebooks.fees_and_bribs.constants import GNOSIS_CORE_POOLS\n",
    "from notebooks.fees_and_bribs.constants import MAINNET_CORE_POOLS\n",
    "from notebooks.fees_and_bribs.constants import POLYGON_CORE_POOLS\n",
    "from notebooks.fees_and_bribs.constants import AVAX_CORE_POOLS\n",
    "\n",
    "load_dotenv()\n",
    "arb_web3 = Web3(Web3.HTTPProvider(os.environ[\"ARBNODEURL\"]))\n",
    "eth_web3 = Web3(Web3.HTTPProvider(os.environ[\"ETHNODEURL\"]))\n",
    "base_web3 = Web3(Web3.HTTPProvider(os.environ[\"BASENODEURL\"]))\n",
    "gnosis_web3 = Web3(Web3.HTTPProvider(os.environ[\"GNOSISNODEURL\"]))\n",
    "avax_web3 = Web3(Web3.HTTPProvider(os.environ[\"AVALANCHENODEURL\"]))\n",
    "poly_web3 = Web3(Web3.HTTPProvider(\"https://polygon-rpc.com\"))\n",
    "poly_web3.middleware_onion.inject(geth_poa_middleware, layer=0)\n",
    "\n",
    "# ARBITRUM\n",
    "# arb_block_now = arb_web3.eth.block_number - 1000\n",
    "timestamp_now = 1694790000\n",
    "arb_block = get_block_by_ts(timestamp_now, \"arbitrum\")  # 18 August 2023\n",
    "# Given Arb block time, we want to look back 2 weeks:\n",
    "arb_timestamp_2_weeks_ago = timestamp_now - (2 * 7 * 24 * 60 * 60)\n",
    "arb_block_2_weeks_ago = get_block_by_ts(arb_timestamp_2_weeks_ago, \"arbitrum\")\n",
    "# Convert to datetime:\n",
    "arb_datetime_now = datetime.datetime.fromtimestamp(timestamp_now)\n",
    "arb_datetime_2_weeks_ago = datetime.datetime.fromtimestamp(arb_timestamp_2_weeks_ago)\n",
    "# MAINNET\n",
    "mainnet_block = get_block_by_ts(timestamp_now, \"mainnet\")\n",
    "# Given mainnet block time, we want to look back 2 weeks:\n",
    "mainnet_timestamp_2_weeks_ago = arb_timestamp_2_weeks_ago\n",
    "mainnet_block_2_weeks_ago = get_block_by_ts(mainnet_timestamp_2_weeks_ago, \"mainnet\")\n",
    "# Convert to datetime:\n",
    "mainnet_datetime_now = datetime.datetime.fromtimestamp(timestamp_now)\n",
    "mainnet_datetime_2_weeks_ago = datetime.datetime.fromtimestamp(mainnet_timestamp_2_weeks_ago)\n",
    "\n",
    "# BASE\n",
    "base_block = get_block_by_ts(timestamp_now, \"base\")\n",
    "# Given base block time, we want to look back 2 weeks:\n",
    "base_timestamp_2_weeks_ago = arb_timestamp_2_weeks_ago\n",
    "base_block_2_weeks_ago = get_block_by_ts(base_timestamp_2_weeks_ago, \"base\")\n",
    "# Convert to datetime:\n",
    "base_datetime_now = datetime.datetime.fromtimestamp(timestamp_now)\n",
    "base_datetime_2_weeks_ago = datetime.datetime.fromtimestamp(base_timestamp_2_weeks_ago)\n",
    "\n",
    "# POLYGON\n",
    "poly_block = get_block_by_ts(timestamp_now, \"polygon\")\n",
    "# Given polygon block time, we want to look back 2 weeks:\n",
    "poly_timestamp_2_weeks_ago = arb_timestamp_2_weeks_ago\n",
    "poly_block_2_weeks_ago = get_block_by_ts(poly_timestamp_2_weeks_ago, \"polygon\")\n",
    "# Convert to datetime:\n",
    "poly_datetime_now = datetime.datetime.fromtimestamp(timestamp_now)\n",
    "poly_datetime_2_weeks_ago = datetime.datetime.fromtimestamp(poly_timestamp_2_weeks_ago)\n",
    "\n",
    "# GNOSIS\n",
    "gnosis_block = get_block_by_ts(timestamp_now, \"gnosis\")\n",
    "# Given gnosis block time, we want to look back 2 weeks:\n",
    "gnosis_timestamp_2_weeks_ago = arb_timestamp_2_weeks_ago\n",
    "gnosis_block_2_weeks_ago = get_block_by_ts(gnosis_timestamp_2_weeks_ago, \"gnosis\")\n",
    "# Convert to datetime:\n",
    "gnosis_datetime_now = datetime.datetime.fromtimestamp(timestamp_now)\n",
    "gnosis_datetime_2_weeks_ago = datetime.datetime.fromtimestamp(gnosis_timestamp_2_weeks_ago)\n",
    "\n",
    "# Avalanche\n",
    "avax_block = get_block_by_ts(timestamp_now, \"avalanche\")\n",
    "# Given avalanche block time, we want to look back 2 weeks:\n",
    "avax_timestamp_2_weeks_ago = arb_timestamp_2_weeks_ago\n",
    "avax_block_2_weeks_ago = get_block_by_ts(avax_timestamp_2_weeks_ago, \"avalanche\")\n",
    "# Convert to datetime:\n",
    "avax_datetime_now = datetime.datetime.fromtimestamp(timestamp_now)\n",
    "avax_datetime_2_weeks_ago = datetime.datetime.fromtimestamp(avax_timestamp_2_weeks_ago)\n",
    "\n",
    "print(\"Collecting bpt prices for Gnosis\")\n",
    "gnosis_bpt_twap_prices = {}\n",
    "for gnosis_pool in GNOSIS_CORE_POOLS:\n",
    "    gnosis_bpt_twap_prices[gnosis_pool] = get_twap_bpt_price(gnosis_pool, 'gnosis', gnosis_web3,\n",
    "                                                             start_date=gnosis_datetime_now,\n",
    "                                                             block_number=gnosis_block)\n",
    "\n",
    "print(\"Collecting bpt prices for Avalanche\")\n",
    "avax_bpt_twap_prices = {}\n",
    "for avax_pool in AVAX_CORE_POOLS:\n",
    "    avax_bpt_twap_prices[avax_pool] = get_twap_bpt_price(avax_pool, 'avalanche', avax_web3,\n",
    "                                                         start_date=avax_datetime_now, block_number=avax_block)\n",
    "print(\"Collecting bpt prices for Base\")\n",
    "base_bpt_twap_prices = {}\n",
    "for base_pool in BASE_CORE_POOLS:\n",
    "    base_bpt_twap_prices[base_pool] = get_twap_bpt_price(base_pool, 'base', base_web3,\n",
    "                                                         start_date=base_datetime_now, block_number=base_block)\n",
    "print(\"Collecting bpt prices for Arbitrum\")\n",
    "arb_bpt_twap_prices = {}\n",
    "for arb_pool in ARB_CORE_POOLS:\n",
    "    arb_bpt_twap_prices[arb_pool] = get_twap_bpt_price(arb_pool, 'arbitrum', arb_web3,\n",
    "                                                       start_date=arb_datetime_now,\n",
    "                                                       block_number=arb_block)\n",
    "\n",
    "print(\"Collecting bpt prices for Mainnet\")\n",
    "mainnet_bpt_twap_prices = {}\n",
    "for mainnet_pool in MAINNET_CORE_POOLS:\n",
    "    mainnet_bpt_twap_prices[mainnet_pool] = get_twap_bpt_price(mainnet_pool, 'mainnet', eth_web3,\n",
    "                                                               start_date=mainnet_datetime_now,\n",
    "                                                               block_number=mainnet_block)\n",
    "print(\"Collecting bpt prices for Polygon\")\n",
    "polygon_bpt_twap_prices = {}\n",
    "for polygon_pool in POLYGON_CORE_POOLS:\n",
    "    polygon_bpt_twap_prices[polygon_pool] = get_twap_bpt_price(polygon_pool, 'polygon', poly_web3,\n",
    "                                                               start_date=poly_datetime_now,\n",
    "                                                               block_number=poly_block)\n",
    "\n",
    "# Convert to dataframe and print, merge all three dataframes\n",
    "arb_bpt_twap_prices_df = pd.DataFrame.from_dict(arb_bpt_twap_prices, orient='index')\n",
    "mainnet_bpt_twap_prices_df = pd.DataFrame.from_dict(mainnet_bpt_twap_prices, orient='index')\n",
    "polygon_bpt_twap_prices_df = pd.DataFrame.from_dict(polygon_bpt_twap_prices, orient='index')\n",
    "base_bpt_twap_prices_df = pd.DataFrame.from_dict(base_bpt_twap_prices, orient='index')\n",
    "gnosis_bpt_twap_prices_df = pd.DataFrame.from_dict(gnosis_bpt_twap_prices, orient='index')\n",
    "avax_bpt_twap_prices_df = pd.DataFrame.from_dict(avax_bpt_twap_prices, orient='index')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-18T15:34:39.040930Z"
    }
   },
   "id": "39d87004addaae1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetching data from the Balancer subgraphs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cde5ffca807e3849"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks.fees_and_bribs.constants import BASE_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import POLYGON_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import ARB_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import MAINNET_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import GNOSIS_BALANCER_GRAPH_URL\n",
    "from notebooks.fees_and_bribs.constants import AVALANCHE_BALANCER_GRAPH_URL\n",
    "from notebooks import POOLS_SNAPSHOTS_QUERY\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Optional\n",
    "\n",
    "from gql import Client\n",
    "from gql import gql\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "\n",
    "\n",
    "# Fetch all the data from the balancer subgraph\n",
    "def make_gql_client(url: str) -> Optional[Client]:\n",
    "    transport = RequestsHTTPTransport(url=url, retries=3)\n",
    "    return Client(\n",
    "        transport=transport, fetch_schema_from_transport=True, execute_timeout=60\n",
    "    )\n",
    "\n",
    "\n",
    "def get_balancer_pool_snapshots(block: int, graph_url: str) -> Optional[List[Dict]]:\n",
    "    client = make_gql_client(graph_url)\n",
    "    all_pools = []\n",
    "    limit = 1000\n",
    "    offset = 0\n",
    "    while True:\n",
    "        result = client.execute(\n",
    "            gql(POOLS_SNAPSHOTS_QUERY.format(first=limit, skip=offset, block=block)))\n",
    "        all_pools.extend(result['poolSnapshots'])\n",
    "        offset += limit\n",
    "        if offset >= 5000:\n",
    "            break\n",
    "        if len(result['poolSnapshots']) < limit - 1:\n",
    "            break\n",
    "    return all_pools\n",
    "\n",
    "\n",
    "arbi_pool_snapshots_now = get_balancer_pool_snapshots(arb_block, ARB_BALANCER_GRAPH_URL)\n",
    "arbi_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(arb_block_2_weeks_ago), ARB_BALANCER_GRAPH_URL)\n",
    "\n",
    "mainnet_pool_snapshots_now = get_balancer_pool_snapshots(mainnet_block, MAINNET_BALANCER_GRAPH_URL)\n",
    "mainnet_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(mainnet_block_2_weeks_ago),\n",
    "                                                                 MAINNET_BALANCER_GRAPH_URL)\n",
    "\n",
    "polygon_pool_snapshots_now = get_balancer_pool_snapshots(poly_block, POLYGON_BALANCER_GRAPH_URL)\n",
    "polygon_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(poly_block_2_weeks_ago),\n",
    "                                                                 POLYGON_BALANCER_GRAPH_URL)\n",
    "\n",
    "base_pool_snapshots_now = get_balancer_pool_snapshots(base_block, BASE_BALANCER_GRAPH_URL)\n",
    "base_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(base_block_2_weeks_ago),\n",
    "                                                              BASE_BALANCER_GRAPH_URL)\n",
    "\n",
    "gnosis_pool_snapshots_now = get_balancer_pool_snapshots(gnosis_block, GNOSIS_BALANCER_GRAPH_URL)\n",
    "gnosis_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(gnosis_block_2_weeks_ago),\n",
    "                                                                GNOSIS_BALANCER_GRAPH_URL)\n",
    "\n",
    "avax_pool_snapshots_now = get_balancer_pool_snapshots(avax_block, AVALANCHE_BALANCER_GRAPH_URL)\n",
    "avax_pool_snapshots_2_weeks_ago = get_balancer_pool_snapshots(int(avax_block_2_weeks_ago),\n",
    "                                                              AVALANCHE_BALANCER_GRAPH_URL)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e1e0b8b90f62234c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract fee data for CORE pools:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5333a7de445454d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from decimal import Decimal\n",
    "from notebooks import fetch_token_price_balgql\n",
    "\n",
    "\n",
    "def collect_fee_info(pools: list[str], chain: str, pools_now: list[dict], pools_shifted: list[dict],\n",
    "                     start_date: datetime.datetime) -> tuple[dict, dict]:\n",
    "    # Iterate through snapshots now and 2 weeks ago and extract fee data, by subtracting today's fee data from 2 weeks ago\n",
    "    # and then summing across all pools\n",
    "    fees = {}\n",
    "    token_fees = defaultdict(list)\n",
    "    for pool in pools:\n",
    "        current_fees_snapshots = [x for x in pools_now if x['pool']['id'] == pool]\n",
    "        current_fees_snapshots.sort(key=lambda x: x['timestamp'], reverse=True)\n",
    "        fees_2_weeks_ago = [x for x in pools_shifted if x['pool']['id'] == pool]\n",
    "        fees_2_weeks_ago.sort(key=lambda x: x['timestamp'], reverse=True)\n",
    "        # Take first element of list, which is the most recent snapshot\n",
    "        if not current_fees_snapshots or not fees_2_weeks_ago:\n",
    "            continue\n",
    "        pool_snapshot_now = current_fees_snapshots[0]\n",
    "        pool_snapshot_2_weeks_ago = fees_2_weeks_ago[0]\n",
    "        # Calculate fees\n",
    "        pool_fee = float(pool_snapshot_now['protocolFee']) - float(pool_snapshot_2_weeks_ago['protocolFee'])\n",
    "        pool_swap_fee = float(pool_snapshot_now['swapFees']) - float(pool_snapshot_2_weeks_ago['swapFees'])\n",
    "        # Now we need to collect token fee info. Let's start with BPT tokens, which is Balancer pool token. Notice,\n",
    "        # That totalProtocolFeePaidInBPT can be null, so we need to check for that\n",
    "        bpt_token_fee = 0\n",
    "        bpt_price_usd = arb_bpt_twap_prices[pool] if chain == 'arbitrum' else mainnet_bpt_twap_prices[\n",
    "            pool] if chain == 'mainnet' else polygon_bpt_twap_prices[pool] if chain == 'polygon' else \\\n",
    "            base_bpt_twap_prices[pool] if chain == 'base' else gnosis_bpt_twap_prices[pool] if chain == 'gnosis' else \\\n",
    "            avax_bpt_twap_prices[pool]\n",
    "        if bpt_price_usd is None:\n",
    "            bpt_price_usd = 0\n",
    "        if pool_snapshot_now['pool']['totalProtocolFeePaidInBPT'] is not None and pool_snapshot_2_weeks_ago['pool'][\n",
    "            'totalProtocolFeePaidInBPT'] is not None:\n",
    "            bpt_token_fee = float(pool_snapshot_now['pool']['totalProtocolFeePaidInBPT']) - float(\n",
    "                pool_snapshot_2_weeks_ago['pool']['totalProtocolFeePaidInBPT'])\n",
    "            token_fees[pool_snapshot_now['pool']['symbol']].append({\n",
    "                'token': pool_snapshot_now['pool']['symbol'],\n",
    "                'token_fee': bpt_token_fee,\n",
    "                'token_price': bpt_price_usd,\n",
    "                'token_fee_in_usd': Decimal(bpt_token_fee) * bpt_price_usd,\n",
    "                'token_addr': pool_snapshot_now['pool']['address'],\n",
    "                'time_from': arb_datetime_2_weeks_ago,\n",
    "                'time_to': arb_datetime_now,\n",
    "                'chain': chain,\n",
    "            })\n",
    "        # Now collect fee info about fees paid in pool tokens. Pool tokens fee info is in pool.tokens dictionary. This will be separate dictionary\n",
    "        else:\n",
    "            bpt_price_usd = 0\n",
    "            for token_data in pool_snapshot_now['pool']['tokens']:\n",
    "                token_data_2_weeks_ago = \\\n",
    "                    [t for t in pool_snapshot_2_weeks_ago['pool']['tokens'] if t['address'] == token_data['address']][0]\n",
    "                token_fee = float(token_data.get('paidProtocolFees', None)) - float(\n",
    "                    token_data_2_weeks_ago.get('paidProtocolFees', None))\n",
    "                # Get twap token price from CoinGecko\n",
    "                token_price = fetch_token_price_balgql(token_data['address'], chain, start_date) or 0\n",
    "                token_fees[pool_snapshot_now['pool']['symbol']].append({\n",
    "                    'token': token_data['symbol'],\n",
    "                    'token_fee': token_fee,\n",
    "                    'token_price': token_price,\n",
    "                    'token_fee_in_usd': Decimal(token_fee) * token_price if token_price is not None else 0,\n",
    "                    'token_addr': token_data['address'],\n",
    "                    'time_from': arb_datetime_2_weeks_ago,\n",
    "                    'time_to': arb_datetime_now,\n",
    "                    'chain': chain,\n",
    "                })\n",
    "        # Calculate non-BPT fees in USD\n",
    "        fees[pool_snapshot_now['pool']['symbol']] = {\n",
    "            'pool_fee': round(pool_fee, 2),\n",
    "            'swap_fee': round(pool_swap_fee, 2),\n",
    "            'bpt_token_fee': round(bpt_token_fee, 2),\n",
    "            # Get fee in USD by multiplying bpt_token_fee by price of BPT token taken from twap_bpt_price\n",
    "            'bpt_token_fee_in_usd': round(Decimal(bpt_token_fee) * bpt_price_usd, 2),\n",
    "            'token_fees_in_usd': round(sum([x['token_fee_in_usd'] for x in\n",
    "                                            token_fees[\n",
    "                                                pool_snapshot_now['pool']['symbol']]]) if bpt_price_usd == 0 else 0, 2),\n",
    "            'time_from': arb_datetime_2_weeks_ago,\n",
    "            'time_to': arb_datetime_now,\n",
    "            'chain': chain,\n",
    "            'token_fees': token_fees[pool_snapshot_now['pool']['symbol']],\n",
    "            'pool_addr': pool_snapshot_now['pool']['address'],\n",
    "        }\n",
    "    return fees\n",
    "\n",
    "\n",
    "arb_fees = collect_fee_info(ARB_CORE_POOLS, 'arbitrum', arbi_pool_snapshots_now,\n",
    "                            arbi_pool_snapshots_2_weeks_ago, arb_datetime_now)\n",
    "mainnet_fees = collect_fee_info(MAINNET_CORE_POOLS, 'mainnet', mainnet_pool_snapshots_now,\n",
    "                                mainnet_pool_snapshots_2_weeks_ago, mainnet_datetime_now)\n",
    "polygon_fees = collect_fee_info(POLYGON_CORE_POOLS, 'polygon', polygon_pool_snapshots_now,\n",
    "                                polygon_pool_snapshots_2_weeks_ago, poly_datetime_now)\n",
    "base_fees = collect_fee_info(BASE_CORE_POOLS, 'base', base_pool_snapshots_now, base_pool_snapshots_2_weeks_ago,\n",
    "                             base_datetime_now)\n",
    "gnosis_fees = collect_fee_info(GNOSIS_CORE_POOLS, 'gnosis', gnosis_pool_snapshots_now,\n",
    "                               gnosis_pool_snapshots_2_weeks_ago, gnosis_datetime_now)\n",
    "avax_fees = collect_fee_info(AVAX_CORE_POOLS, 'avalanche', avax_pool_snapshots_now,\n",
    "                             avax_pool_snapshots_2_weeks_ago, avax_datetime_now)\n",
    "# Convert to dataframe, sort by chain and pool fee\n",
    "joint_fees = {**arb_fees, **mainnet_fees, **polygon_fees, **base_fees, **gnosis_fees, **avax_fees}\n",
    "joint_fees_df = pd.DataFrame.from_dict(joint_fees, orient='index')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e79b2f6a4ead2cad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove `token_fees` field from dataframe, as it's too big\n",
    "joint_fees_df_copy = joint_fees_df.drop(columns=['token_fees'])\n",
    "# Display all rows in dataframe\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "joint_fees_df_copy.sort_values(by=['chain', 'pool_fee'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "52fccc19e5e6b4f2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now let's calculate bribes paid to the pools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97a5370819f28ffc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks import calculate_aura_vebal_share\n",
    "\n",
    "aura_vebal_share = calculate_aura_vebal_share(eth_web3, mainnet_block)\n",
    "\n",
    "# Bribes are split per chain and per pool, with each pool getting a share of the bribe proportional to its share of fees\n",
    "# paid by all pools on that chain. For example, if pool A paid 10% of all fees on Arbitrum, it will get 10% of the bribes. That 10% will be distributed between aura and vebal, proportional to their share of the bribe.\n",
    "FEE = Decimal(0.5)  # 50% goes to fees\n",
    "\n",
    "\n",
    "# Let's calculate share of fees paid by each pool on each chain\n",
    "def calc_and_split_bribes(fees: Dict, chain: str, fees_to_distribute: Decimal) -> Dict[str, Dict]:\n",
    "    pool_bribs = {}\n",
    "    # Calculate pool share in fees\n",
    "    total_fees = sum([data['pool_fee'] for pool, data in fees.items()])\n",
    "    for pool, data in fees.items():\n",
    "        pool_fees = data['bpt_token_fee_in_usd'] + data['token_fees_in_usd']\n",
    "        pool_share = pool_fees / Decimal(total_fees)\n",
    "        # Split fees between aura and bal fees\n",
    "        pool_bribs[pool] = {\n",
    "            \"chain\": chain,\n",
    "            \"aura_bribes\": round(pool_share * fees_to_distribute * aura_vebal_share * FEE, 2),\n",
    "            \"bal_bribes\": round(pool_share * fees_to_distribute * (1 - aura_vebal_share) * FEE, 2),\n",
    "            \"pool_fees_collected\": pool_fees,\n",
    "            \"revenue_fees\": pool_fees * FEE,\n",
    "            # \"pool_share\": f\"{round(pool_share * 100, 2)}%\",\n",
    "            \"pool_addr\": data['pool_addr'],\n",
    "        }\n",
    "    return pool_bribs\n",
    "\n",
    "# TODO: Move to constants\n",
    "mainnet_bribes = calc_and_split_bribes(mainnet_fees, 'mainnet', Decimal(81763))\n",
    "arb_bribes = calc_and_split_bribes(arb_fees, 'arbitrum', Decimal(18523))\n",
    "polygon_bribes = calc_and_split_bribes(polygon_fees, 'polygon', Decimal(5162.59))\n",
    "base_bribes = calc_and_split_bribes(base_fees, 'base', Decimal(67118))\n",
    "gnosis_bribes = calc_and_split_bribes(gnosis_fees, 'gnosis', Decimal(597))\n",
    "avax_bribes = calc_and_split_bribes(avax_fees, 'avalanche', Decimal(10297))\n",
    "# Convert to dataframe\n",
    "joint_bribes_data = {**arb_bribes, **mainnet_bribes, **polygon_bribes, **base_bribes, **gnosis_bribes, **avax_bribes}\n",
    "# Sort by chain:\n",
    "joint_bribes_data = {k: v for k, v in sorted(joint_bribes_data.items(), key=lambda item: item[1]['chain'])}\n",
    "joint_bribes_df = pd.DataFrame.from_dict(joint_bribes_data, orient='index')\n",
    "# Sort by chain\n",
    "# Dump into csv and prefix with dates\n",
    "joint_bribes_df.to_csv(f'./output/bribes_{arb_datetime_2_weeks_ago.date()}_{arb_datetime_now.date()}.csv')\n",
    "joint_bribes_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "efdef306c522076a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from notebooks import fetch_all_pools_info\n",
    "\n",
    "mainnet_pools_info = fetch_all_pools_info('mainnet')\n",
    "arb_pools_info = fetch_all_pools_info('arbitrum')\n",
    "polygon_pools_info = fetch_all_pools_info('polygon')\n",
    "base_pools_info = fetch_all_pools_info('base')\n",
    "gnosis_pools_info = fetch_all_pools_info('gnosis')\n",
    "avax_pools_info = fetch_all_pools_info('avalanche')\n",
    "\n",
    "mainnet_gauges = {pool_info['address']: pool_info['gauge']['address'] for pool_info in mainnet_pools_info}\n",
    "arb_gauges = {pool_info['address']: pool_info['gauge']['address'] for pool_info in arb_pools_info}\n",
    "polygon_gauges = {pool_info['address']: pool_info['gauge']['address'] for pool_info in polygon_pools_info}\n",
    "base_gauges = {pool_info['address']: pool_info['gauge']['address'] for pool_info in base_pools_info}\n",
    "gnosis_gauges = {pool_info['address']: pool_info['gauge']['address'] for pool_info in gnosis_pools_info}\n",
    "avax_gauges = {pool_info['address']: pool_info['gauge']['address'] for pool_info in avax_pools_info}\n",
    "print(mainnet_gauges)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "93d3b07a2ccb9a32"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
